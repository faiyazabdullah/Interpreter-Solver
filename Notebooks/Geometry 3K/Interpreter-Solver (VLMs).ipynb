{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-09T06:08:05.977854Z",
     "iopub.status.busy": "2025-07-09T06:08:05.977569Z",
     "iopub.status.idle": "2025-07-09T06:09:12.388889Z",
     "shell.execute_reply": "2025-07-09T06:09:12.388206Z",
     "shell.execute_reply.started": "2025-07-09T06:08:05.977831Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T06:22:21.984810Z",
     "iopub.status.busy": "2025-07-09T06:22:21.984090Z",
     "iopub.status.idle": "2025-07-09T06:25:47.795905Z",
     "shell.execute_reply": "2025-07-09T06:25:47.795301Z",
     "shell.execute_reply.started": "2025-07-09T06:22:21.984786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install unsloth\n",
    "\n",
    "from unsloth import FastVisionModel\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from transformers import TextStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T06:25:47.797866Z",
     "iopub.status.busy": "2025-07-09T06:25:47.797129Z",
     "iopub.status.idle": "2025-07-09T06:26:40.597663Z",
     "shell.execute_reply": "2025-07-09T06:26:40.596988Z",
     "shell.execute_reply.started": "2025-07-09T06:25:47.797843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the vision model\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit\",\n",
    "    # \"unsloth/Qwen2.5-VL-32B-Instruct-bnb-4bit\",\n",
    "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
    "    # T4x2 specific optimizations\n",
    "    device_map=\"balanced\",  # Distribute across both T4 GPUs\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True,\n",
    "    # Aggressive memory limits for T4x2\n",
    "    max_memory={\n",
    "        0: \"13GB\",  # GPU 0 - leave some buffer\n",
    "        1: \"13GB\",  # GPU 1 - leave some buffer\n",
    "        \"cpu\": \"20GB\"\n",
    "    },\n",
    "    offload_folder=\"./offload_temp\",\n",
    "    offload_state_dict=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T06:26:40.598698Z",
     "iopub.status.busy": "2025-07-09T06:26:40.598508Z",
     "iopub.status.idle": "2025-07-09T06:26:40.605041Z",
     "shell.execute_reply": "2025-07-09T06:26:40.604489Z",
     "shell.execute_reply.started": "2025-07-09T06:26:40.598682Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total params: {total/1e9:.2f} billion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T06:26:40.606375Z",
     "iopub.status.busy": "2025-07-09T06:26:40.605737Z",
     "iopub.status.idle": "2025-07-09T06:26:40.615370Z",
     "shell.execute_reply": "2025-07-09T06:26:40.614597Z",
     "shell.execute_reply.started": "2025-07-09T06:26:40.606348Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 'x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T06:26:40.617988Z",
     "iopub.status.busy": "2025-07-09T06:26:40.617135Z",
     "iopub.status.idle": "2025-07-09T06:26:40.633294Z",
     "shell.execute_reply": "2025-07-09T06:26:40.632750Z",
     "shell.execute_reply.started": "2025-07-09T06:26:40.617968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Enable for inference\n",
    "FastVisionModel.for_inference(model)\n",
    "model.eval()  # set to eval mode\n",
    "\n",
    "def solve_geometry_problem_with_image_and_predicates(image_path, predicates, question, choices):\n",
    "    \"\"\"\n",
    "    Solve geometry problem using Qwen2.5-VL Model with both image and predicates\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the geometry problem image\n",
    "        predicates (str): Formal logical predicates describing the geometry\n",
    "        question (str): Question to solve\n",
    "        choices (str): Multiple choice options (A, B, C, D)\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains 'content'\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return {'content': 'Error loading image'}\n",
    "    \n",
    "    # Enhanced prompt combining image and predicates with your specific requirements\n",
    "    prompt = f\"\"\"You are an expert AI mathematician solving geometric problems through rigorous deductive reasoning.\n",
    "\n",
    "GEOMETRIC FIGURE IMAGE:\n",
    "The image shows a geometric figure. Use this visual information along with the formal predicates below to understand the complete geometric setup.\n",
    "\n",
    "GIVEN PREDICATES: \n",
    "{predicates}\n",
    "\n",
    "QUESTION: \n",
    "{question}\n",
    "\n",
    "CHOICES: \n",
    "{choices}\n",
    "\n",
    "SOLVE THROUGH SYSTEMATIC DEDUCTION:\n",
    "\n",
    "**STEP 1: CRITICAL INFORMATION ANALYSIS**\n",
    "- Examine both the image and predicates to identify the most important geometric relationships\n",
    "- List key measurements, angles, and special constructions (circles, perpendiculars, etc.)\n",
    "- Clearly state what specific value the question asks for\n",
    "- Cross-reference visual elements in the image with the formal predicates\n",
    "\n",
    "**STEP 2: DEDUCTIVE REASONING CHAIN**\n",
    "- Build a logical sequence where each inference follows from previous steps\n",
    "- **JUSTIFY EVERY STEP** by citing specific predicates or geometric theorems\n",
    "- Actively combine predicates to reveal deeper relationships\n",
    "- Use both visual cues from the image and formal relationships from predicates\n",
    "- Example format: \"Since [Predicate A] and [Predicate B], by [Theorem Name], we can conclude [Result]\"\n",
    "- Show all mathematical calculations as part of this logical chain\n",
    "- **NO ASSUMPTIONS** - every step must be explicitly supported\n",
    "\n",
    "**STEP 3: CONCLUSION AND SELECTION**\n",
    "- State your final calculated answer based on the deductive chain\n",
    "- Select the matching choice from A, B, C, or D\n",
    "- If no exact match, choose the closest option and note any discrepancy\n",
    "\n",
    "**DEDUCTIVE REASONING GUIDELINES:**\n",
    "- **Synthesize Information:** Don't just list predicates - combine them to find new relationships\n",
    "- **Use Given Measurements:** Pay special attention to provided angle/length measurements\n",
    "- **Apply Geometric Theorems:** Use inscribed angle, central angle, perpendicular, circle, and triangle theorems\n",
    "- **Logical Flow:** Each step must logically follow from established facts\n",
    "- **Explicit Justification:** Always state WHY each inference is valid\n",
    "- **Visual-Predicate Integration:** Use the image to understand spatial relationships and predicates for precise logical reasoning\n",
    "\n",
    "⚠️ CRITICAL OUTPUT FORMAT REQUIREMENT ⚠️\n",
    "YOU MUST END YOUR RESPONSE WITH EXACTLY ONE OF THESE FOUR LINES:\n",
    "Final Answer: A\n",
    "Final Answer: B\n",
    "Final Answer: C\n",
    "Final Answer: D\n",
    "\n",
    "❌ ABSOLUTELY FORBIDDEN - DO NOT USE:\n",
    "- \"The final answer is $\\\\boxed{{14}}$\"\n",
    "- \"The final answer is $\\\\boxed{{A}}$\"\n",
    "- \"$\\\\boxed{{A}}$\"\n",
    "- \"\\\\boxed{{A}}\"\n",
    "- \"(A)\"\n",
    "- \"A is correct.\"\n",
    "- \"Final Answer: The answer is A\"\n",
    "- Any LaTeX formatting\n",
    "- Any mathematical notation\n",
    "- Any additional text after the letter\n",
    "\n",
    "✅ REQUIRED FORMAT EXAMPLES:\n",
    "If you determine the answer is choice A: \"Final Answer: A\"\n",
    "If you determine the answer is choice B: \"Final Answer: B\"\n",
    "If you determine the answer is choice C: \"Final Answer: C\"\n",
    "If you determine the answer is choice D: \"Final Answer: D\"\n",
    "\n",
    "IMPORTANT: Your response must end with exactly \"Final Answer: [SINGLE LETTER]\" - nothing else on that line. Do not include any boxed notation, LaTeX, or mathematical formatting in your final line.\n",
    "\n",
    "Begin your analysis now and remember to end with the exact required format.\n",
    "\"\"\"\n",
    "\n",
    "    # Create messages for Qwen2.5-VL\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": prompt}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Apply chat template\n",
    "    input_text = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    # Prepare inputs with image\n",
    "    inputs = tokenizer(\n",
    "        image,\n",
    "        input_text,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Generate response with Qwen2.5-VL parameters\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=5000,\n",
    "            temperature=0.8,\n",
    "            min_p=0.1,\n",
    "            use_cache=True,\n",
    "            do_sample=True,\n",
    "        )\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Decode only the generated tokens (excluding input)\n",
    "    generated_tokens = outputs[:, inputs.input_ids.shape[-1]:]\n",
    "    content = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0].strip()\n",
    "\n",
    "    return {\n",
    "        'content': content\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T06:26:40.634370Z",
     "iopub.status.busy": "2025-07-09T06:26:40.634111Z",
     "iopub.status.idle": "2025-07-09T06:26:40.646724Z",
     "shell.execute_reply": "2025-07-09T06:26:40.646096Z",
     "shell.execute_reply.started": "2025-07-09T06:26:40.634348Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_answer_letter(content):\n",
    "    \"\"\"\n",
    "    Enhanced function to extract an answer letter from a model's output.\n",
    "    It includes patterns for plain text, markdown, and LaTeX formats to ensure\n",
    "    the answer is captured reliably.\n",
    "    Args:\n",
    "        content (str): The model's output content.\n",
    "    Returns:\n",
    "        str: The extracted answer letter (A, B, C, or D), or an empty string if not found.\n",
    "    \"\"\"\n",
    "    # Enhanced list of regex patterns to try, in order of preference\n",
    "    patterns = [\n",
    "        # LaTeX box patterns - FIXED PATTERNS\n",
    "        r\"\\\\boxed\\{([A-D])\\}\",                # Handles '\\boxed{A}' or '$\\boxed{A}$'\n",
    "        r\"\\$\\\\boxed\\{([A-D])\\}\\$\",            # Handles '$\\boxed{A}$'\n",
    "        r\"\\\\boxed\\{\\\\text\\{([A-D])\\}\\}\",      # Handles '\\boxed{\\text{A}}'\n",
    "        r\"\\$\\\\boxed\\{\\\\text\\{([A-D])\\}\\}\\$\",  # Handles '$\\boxed{\\text{A}}$'\n",
    "        r\"The final answer is \\$\\\\boxed\\{([A-D])\\}\\$\",  # 'The final answer is $\\boxed{A}$'\n",
    "        r\"The final answer is \\\\boxed\\{([A-D])\\}\",      # 'The final answer is \\boxed{A}'\n",
    "        r\"The final answer is \\$\\\\boxed\\{(\\d+)\\}\\$\",    # Extract from numeric boxed answers\n",
    "        \n",
    "        # Standard patterns\n",
    "        r\"Final Answer:\\s*([A-D])\\b\",        # Final Answer: A\n",
    "        r\"Final Answer:\\s*\\*\\*([A-D])\\*\\*\",  # Final Answer: **A**\n",
    "        r\"Answer:\\s*([A-D])\\b\",              # Answer: A\n",
    "        r\"Answer:\\s*\\*\\*([A-D])\\*\\*\",        # Answer: **A**\n",
    "        r\"Answer:\\s*\\*([A-D])\\*\",            # Answer: *A*\n",
    "        r\"Answer:\\s*_([A-D])_\",              # Answer: _A_\n",
    "        r\"Answer:\\s*\\(([A-D])\\)\",            # Answer: (A)\n",
    "        r\"Answer:\\s*([A-D])\\.\",              # Answer: A.\n",
    "        \n",
    "        # Sentence-based patterns\n",
    "        r\"The answer is\\s*([A-D])\\b\",        # The answer is A\n",
    "        r\"The correct answer is\\s*([A-D])\\b\", # The correct answer is A\n",
    "        r\"\\b([A-D])\\s*is the correct\",       # A is the correct\n",
    "        \n",
    "        # Choice/option patterns\n",
    "        r\"choice\\s*([A-D])\\b\",               # choice A\n",
    "        r\"option\\s*([A-D])\\b\",               # option A\n",
    "        r\"select\\s*([A-D])\\b\",               # select A\n",
    "        r\"choose\\s*([A-D])\\b\",               # choose A\n",
    "        \n",
    "        # Concluding word patterns\n",
    "        r\"Therefore,?\\s*([A-D])\\b\",          # Therefore, A\n",
    "        r\"Thus,?\\s*([A-D])\\b\",               # Thus, A\n",
    "        r\"Hence,?\\s*([A-D])\\b\",              # Hence, A\n",
    "    ]\n",
    "    \n",
    "    # Try each pattern in the defined order\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, content, re.IGNORECASE)\n",
    "        if match:\n",
    "            captured = match.group(1).upper()\n",
    "            # Handle numeric answers by mapping to choices if needed\n",
    "            if captured.isdigit():\n",
    "                # You might need to implement logic here to map numbers to letters\n",
    "                # based on your specific answer choices\n",
    "                continue\n",
    "            return captured\n",
    "    \n",
    "    # Special handling for boxed numeric answers like \"The final answer is $\\boxed{14}$\"\n",
    "    # Try to match the numeric value with your answer choices\n",
    "    numeric_boxed = re.search(r\"\\\\boxed\\{([0-9.]+)\\}\", content)\n",
    "    if numeric_boxed:\n",
    "        numeric_value = numeric_boxed.group(1)\n",
    "        # You would need to compare this with your actual answer choices\n",
    "        # and return the corresponding letter\n",
    "        # For now, we'll continue to other patterns\n",
    "        pass\n",
    "    \n",
    "    # If no specific pattern matches, look for isolated letters near the end\n",
    "    lines = content.strip().split('\\n')\n",
    "    for line in reversed(lines[-10:]):  # Check the last 10 lines\n",
    "        line = line.strip()\n",
    "        if line in ['A', 'B', 'C', 'D']:\n",
    "            return line\n",
    "        # Check if a line contains only one of the possible answer letters\n",
    "        letters_found = re.findall(r'\\b([A-D])\\b', line)\n",
    "        if len(letters_found) == 1:\n",
    "            return letters_found[0].upper()\n",
    "    \n",
    "    # As a last resort, find any occurrence of A, B, C, or D in the content\n",
    "    all_letters = re.findall(r'\\b([A-D])\\b', content)\n",
    "    if all_letters:\n",
    "        # Return the last one found, as it's most likely the final answer\n",
    "        return all_letters[-1].upper()\n",
    "    \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T06:26:40.647780Z",
     "iopub.status.busy": "2025-07-09T06:26:40.647533Z",
     "iopub.status.idle": "2025-07-09T06:26:40.660860Z",
     "shell.execute_reply": "2025-07-09T06:26:40.660171Z",
     "shell.execute_reply.started": "2025-07-09T06:26:40.647762Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def validate_and_retry_if_needed(image_path, predicates, question, choices, max_retries=3):\n",
    "    \"\"\"\n",
    "    Try to get a valid answer letter, with retries if needed.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        result = solve_geometry_problem_with_image_and_predicates(image_path, predicates, question, choices)\n",
    "        content = result['content']\n",
    "        answer_letter = extract_answer_letter(content)\n",
    "        \n",
    "        if answer_letter in ['A', 'B', 'C', 'D']:\n",
    "            return content, answer_letter\n",
    "        \n",
    "        print(f\"Attempt {attempt + 1} failed to extract valid answer letter\")\n",
    "    \n",
    "    # If all attempts fail, try one more time with a very direct prompt\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        direct_prompt = f\"\"\"Look at this geometry problem image and use the given predicates to answer the question.\n",
    "\n",
    "PREDICATES: {predicates}\n",
    "QUESTION: {question}\n",
    "CHOICES: {choices}\n",
    "\n",
    "⚠️ CRITICAL OUTPUT FORMAT REQUIREMENT ⚠️\n",
    "YOU MUST END YOUR RESPONSE WITH EXACTLY ONE OF THESE FOUR LINES:\n",
    "Final Answer: A\n",
    "Final Answer: B\n",
    "Final Answer: C\n",
    "Final Answer: D\n",
    "\n",
    "❌ ABSOLUTELY FORBIDDEN - DO NOT USE:\n",
    "- \"The final answer is $\\\\boxed{{14}}$\"\n",
    "- \"The final answer is $\\\\boxed{{A}}$\"\n",
    "- \"$\\\\boxed{{A}}$\"\n",
    "- \"\\\\boxed{{A}}\"\n",
    "- \"(A)\"\n",
    "- \"A is correct.\"\n",
    "- \"Final Answer: The answer is A\"\n",
    "- Any LaTeX formatting\n",
    "- Any mathematical notation\n",
    "- Any additional text after the letter\n",
    "\n",
    "✅ REQUIRED FORMAT EXAMPLES:\n",
    "If you determine the answer is choice A: \"Final Answer: A\"\n",
    "If you determine the answer is choice B: \"Final Answer: B\"\n",
    "If you determine the answer is choice C: \"Final Answer: C\"\n",
    "If you determine the answer is choice D: \"Final Answer: D\"\n",
    "\n",
    "IMPORTANT: Your response must end with exactly \"Final Answer: [SINGLE LETTER]\" - nothing else on that line. Do not include any boxed notation, LaTeX, or mathematical formatting in your final line.\n",
    "\n",
    "Begin your analysis now and remember to end with the exact required format.\n",
    "\"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\"},\n",
    "                    {\"type\": \"text\", \"text\": direct_prompt}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "        inputs = tokenizer(image, input_text, add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, max_new_tokens=3000, temperature=0.8, min_p=0.1, use_cache=True, do_sample=True)\n",
    "        \n",
    "        generated_tokens = outputs[:, inputs.input_ids.shape[-1]:]\n",
    "        final_content = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0].strip()\n",
    "        final_letter = extract_answer_letter(final_content)\n",
    "        \n",
    "        return final_content, final_letter if final_letter in ['A', 'B', 'C', 'D'] else 'A'  # Default to A if still fails\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in final retry: {e}\")\n",
    "        return \"Error occurred\", 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T06:26:40.661789Z",
     "iopub.status.busy": "2025-07-09T06:26:40.661547Z",
     "iopub.status.idle": "2025-07-09T06:26:40.675586Z",
     "shell.execute_reply": "2025-07-09T06:26:40.674905Z",
     "shell.execute_reply.started": "2025-07-09T06:26:40.661773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "target_numbers = ['001', '002', '003', '004', '005', '006', '007', '008', '009', '010',\n",
    "                  '011', '012', '013', '014', '015', '016', '017', '018', '019', '020',\n",
    "                  '021', '022', '023', '024', '025', '026', '027', '028', '029', '030',\n",
    "                  '031', '032', '033', '034', '035', '036', '037', '038', '039', '040',\n",
    "                  '041', '042', '043', '044', '045', '046', '047', '048', '049', '050',\n",
    "                  '051', '052', '053', '054', '055', '056', '057', '058', '059', '060',\n",
    "                  '061', '062', '063', '064', '065', '066', '067', '068', '069', '070',\n",
    "                  '071', '072', '073', '074', '075', '076', '077', '078', '079', '080',\n",
    "                  '081', '082', '083', '084', '085', '086', '087', '088', '089', '090',\n",
    "                  '091', '092', '093', '094', '095', '096', '097', '098', '099', '100',\n",
    "                  '101', '102', '103', '104', '105', '106', '107', '108', '109', '110',\n",
    "                  '111', '112', '113', '114', '115', '116', '117', '118', '119', '120',\n",
    "                  '121', '122', '123', '124', '125', '126', '127', '128', '129', '130',\n",
    "                  '131', '132', '133', '134', '135', '136', '137', '138', '139', '140',\n",
    "                  '141', '142', '143', '144', '145', '146', '147', '148', '149', '150',\n",
    "                  '151', '152', '153', '154', '155', '156', '157', '158', '159', '160',\n",
    "                  '161', '162', '163', '164', '165', '166', '167', '168', '169', '170',\n",
    "                  '171', '172', '173', '174', '175', '176', '177', '178', '179', '180',\n",
    "                  '181', '182', '183', '184', '185', '186', '187', '188', '189', '190',\n",
    "                  '191', '192', '193', '194', '195', '196', '197', '198', '199', '200',\n",
    "                  '201', '202', '203', '204', '205', '206', '207', '208', '209', '210',\n",
    "                  '211', '212', '213', '214', '215', '216', '217', '218', '219', '220',\n",
    "                  '221', '222', '223', '224', '225', '226', '227', '228', '229', '230',\n",
    "                  '231', '232', '233', '234', '235', '236', '237', '238', '239', '240',\n",
    "                  '241', '242', '243', '244', '245', '246', '247', '248', '249', '250',\n",
    "                  '251', '252', '253', '254', '255', '256', '257', '258', '259', '260',\n",
    "                  '261', '262', '263', '264', '265', '266', '267', '268', '269', '270',\n",
    "                  '271', '272', '273', '274', '275', '276', '277', '278', '279', '280',\n",
    "                  '281', '282', '283', '284', '285', '286', '287', '288', '289', '290',\n",
    "                  '291', '292', '293', '294', '295', '296', '297', '298', '299', '300',\n",
    "                  '301', '302', '303', '304', '305', '306', '307', '308', '309', '310',\n",
    "                  '311', '312', '313', '314', '315', '316', '317', '318', '319', '320',\n",
    "                  '321', '322', '323', '324', '325', '326', '339', '340', '429', '430',\n",
    "                  '440', '449', '466', '476', '477', '478', '479', '480', '492', '496',\n",
    "                  '498', '499', '507', '516', '517', '518', '521', '523', '524', '525',\n",
    "                  '526', '527', '528', '544', '545', '546', '548', '550', '551', '552',\n",
    "                  '553', '554', '555', '558', '559', '560', '561', '562', '563', '564',\n",
    "                  '565', '566', '567', '572', '574', '575', '576', '577', '579', '581',\n",
    "                  '582', '583', '584', '585', '586', '587', '589', '590', '594', '597',\n",
    "                  '598', '603', '607', '609', '611', '612', '613', '614', '615', '616',\n",
    "                  '617', '618', '620', '621', '622', '751', '752', '753', '754', '755',\n",
    "                  '756', '757', '758', '759', '760', '761', '762', '763', '764', '768',\n",
    "                  '769', '772', '773', '774', '777', '778', '779', '780', '781', '782',\n",
    "                  '783', '784', '785', '786', '787', '788']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T06:26:40.676570Z",
     "iopub.status.busy": "2025-07-09T06:26:40.676318Z",
     "iopub.status.idle": "2025-07-09T06:29:25.805674Z",
     "shell.execute_reply": "2025-07-09T06:29:25.804952Z",
     "shell.execute_reply.started": "2025-07-09T06:26:40.676546Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Input directories\n",
    "    image_dir = \"image\"\n",
    "    predicates_dir = \"predicates_output\"\n",
    "    questions_dir = \"questions\"\n",
    "    choices_dir = \"choices\"\n",
    "    \n",
    "    # Output directories\n",
    "    reasoning_output_dir = \"/kaggle/working/reasoning_output_with_predicates\"\n",
    "    answer_literal_dir = \"/kaggle/working/answer_literal_qwen2_5_vl_predicates\"\n",
    "    os.makedirs(reasoning_output_dir, exist_ok=True)\n",
    "    os.makedirs(answer_literal_dir, exist_ok=True)\n",
    "    \n",
    "    # Iterate over problem numbers 2700 to 3001 (inclusive)\n",
    "    # problems_to_solve = target_numbers[:5]\n",
    "    \n",
    "    for num_str in tqdm(target_numbers):\n",
    "        \n",
    "        # Paths to input files\n",
    "        image_path = os.path.join(image_dir, f\"{num_str}.png\")\n",
    "        predicates_path = os.path.join(predicates_dir, f\"{num_str}.txt\")\n",
    "        ques_path = os.path.join(questions_dir, f\"{num_str}.txt\")\n",
    "        choice_path = os.path.join(choices_dir, f\"{num_str}.txt\")\n",
    "        \n",
    "        # Check if all required files exist\n",
    "        if not all(os.path.exists(path) for path in [image_path, predicates_path, ques_path, choice_path]):\n",
    "            print(f\"Skipping problem {num_str}: Missing input files\")\n",
    "            continue\n",
    "        \n",
    "        # Read inputs\n",
    "        try:\n",
    "            with open(predicates_path, \"r\") as f:\n",
    "                predicates = f.read().strip()\n",
    "            with open(ques_path, \"r\") as f:\n",
    "                question = f.read().strip()\n",
    "            with open(choice_path, \"r\") as f:\n",
    "                choices = f.read().strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading files for problem {num_str}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Solve with validation and retry mechanism\n",
    "        simple_content, answer_letter = validate_and_retry_if_needed(image_path, predicates, question, choices)\n",
    "        \n",
    "        # Build the reasoning file content\n",
    "        reasoning_lines = []\n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        reasoning_lines.append(\"PROBLEM DETAILS:\")\n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        reasoning_lines.append(f\"IMAGE: {image_path}\")\n",
    "        reasoning_lines.append(f\"PREDICATES: {predicates_path}\")\n",
    "        reasoning_lines.append(\"\")\n",
    "        reasoning_lines.append(f\"PREDICATES CONTENT:\\n{predicates}\")\n",
    "        reasoning_lines.append(\"\")\n",
    "        reasoning_lines.append(f\"QUESTION:\\n{question}\")\n",
    "        reasoning_lines.append(\"\")\n",
    "        reasoning_lines.append(f\"CHOICES:\\n{choices}\")\n",
    "        reasoning_lines.append(\"\")\n",
    "        \n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        reasoning_lines.append(\"QWEN2.5-VL MODEL RESPONSE (WITH IMAGE + PREDICATES):\")\n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        reasoning_lines.append(simple_content)\n",
    "        reasoning_lines.append(\"\")\n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        reasoning_lines.append(f\"EXTRACTED ANSWER: {answer_letter}\")\n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        \n",
    "        reasoning_output = \"\\n\".join(reasoning_lines)\n",
    "        \n",
    "        # Write reasoning output to file\n",
    "        reasoning_out_path = os.path.join(reasoning_output_dir, f\"{num_str}.txt\")\n",
    "        with open(reasoning_out_path, \"w\") as f:\n",
    "            f.write(reasoning_output)\n",
    "        \n",
    "        # Validate answer letter\n",
    "        if not answer_letter or answer_letter not in ['A', 'B', 'C', 'D']:\n",
    "            print(f\"Warning: Invalid answer letter '{answer_letter}' for problem {num_str}\")\n",
    "            print(f\"Content: {simple_content[:200]}...\")\n",
    "            # Force a default answer rather than empty\n",
    "            answer_letter = 'A'  # Default fallback\n",
    "        \n",
    "        # Write just the answer letter to a separate file\n",
    "        letter_out_path = os.path.join(answer_literal_dir, f\"{num_str}.txt\")\n",
    "        with open(letter_out_path, \"w\") as f:\n",
    "            f.write(answer_letter)\n",
    "        \n",
    "        print(f\"Problem {num_str}: Answer = {answer_letter}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7590724,
     "sourceId": 12382909,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
