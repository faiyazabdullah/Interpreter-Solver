{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install unsloth\n",
    "\n",
    "from unsloth import FastVisionModel\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from transformers import TextStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Qwen2.5-VL-32B-Instruct-bnb-4bit\",\n",
    "    # \"unsloth/Llama-3.2-11B-Vision-Instruct-bnb-4bit\",\n",
    "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
    "    device_map=\"balanced\",  # Distribute across both T4 GPUs\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True,\n",
    "    # Aggressive memory limits for T4x2\n",
    "    max_memory={\n",
    "        0: \"13GB\",  # GPU 0 - leave some buffer\n",
    "        1: \"13GB\",  # GPU 1 - leave some buffer\n",
    "        \"cpu\": \"20GB\"\n",
    "    },\n",
    "    offload_folder=\"./offload_temp\",\n",
    "    offload_state_dict=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total params: {total/1e9:.2f} billion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Enable for inference\n",
    "FastVisionModel.for_inference(model)\n",
    "model.eval()  # set to eval mode\n",
    "\n",
    "def solve_geometry_problem_with_image(image_path, question, choices):\n",
    "    \"\"\"\n",
    "    Solve geometry problem using Qwen2.5-VL Model with step-by-step reasoning\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the geometry problem image\n",
    "        question (str): Question to solve\n",
    "        choices (str): Multiple choice options (A, B, C, D)\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains 'content'\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return {'content': 'Error loading image'}\n",
    "    \n",
    "    # Enhanced prompt to force choice selection with vision\n",
    "    prompt = f\"\"\"You are an AI mathematician solving geometric problems through visual analysis and logical deduction.\n",
    "\n",
    "GEOMETRY PROBLEM IMAGE:\n",
    "The image shows a geometric figure with various shapes, lines, angles, and measurements. Analyze this image carefully to understand the geometric relationships and constraints.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "ANSWER CHOICES:\n",
    "{choices}\n",
    "\n",
    "SOLUTION STEPS:\n",
    "1. Carefully examine the geometric figure in the image and identify all the given information\n",
    "2. Understand what measurements, angles, or relationships are shown\n",
    "3. Identify what needs to be found based on the question\n",
    "4. Apply relevant geometric theorems, properties, and formulas step by step\n",
    "5. Show all your calculations clearly\n",
    "6. Compare your calculated result with the given answer choices\n",
    "7. Even if your calculated answer doesn't exactly match any choice, select the closest one\n",
    "\n",
    "⚠️ CRITICAL OUTPUT FORMAT REQUIREMENT ⚠️\n",
    "YOU MUST END YOUR RESPONSE WITH EXACTLY ONE OF THESE FOUR LINES:\n",
    "Final Answer: A\n",
    "Final Answer: B\n",
    "Final Answer: C\n",
    "Final Answer: D\n",
    "\n",
    "❌ ABSOLUTELY FORBIDDEN - DO NOT USE:\n",
    "- \"The final answer is $\\\\boxed{{14}}$\"\n",
    "- \"The final answer is $\\\\boxed{{A}}$\"\n",
    "- \"$\\\\boxed{{A}}$\"\n",
    "- \"\\\\boxed{{A}}\"\n",
    "- \"(A)\"\n",
    "- \"A is correct.\"\n",
    "- \"Final Answer: The answer is A\"\n",
    "- Any LaTeX formatting\n",
    "- Any mathematical notation\n",
    "- Any additional text after the letter\n",
    "\n",
    "✅ REQUIRED FORMAT EXAMPLES:\n",
    "If you determine the answer is choice A: \"Final Answer: A\"\n",
    "If you determine the answer is choice B: \"Final Answer: B\"\n",
    "If you determine the answer is choice C: \"Final Answer: C\"\n",
    "If you determine the answer is choice D: \"Final Answer: D\"\n",
    "\n",
    "IMPORTANT: Your response must end with exactly \"Final Answer: [SINGLE LETTER]\" - nothing else on that line. Do not include any boxed notation, LaTeX, or mathematical formatting in your final line.\n",
    "\n",
    "Begin your analysis now and remember to end with the exact required format.\"\"\"\n",
    "\n",
    "    # Create messages for Qwen2.5-VL\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": prompt}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Apply chat template\n",
    "    input_text = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    # Prepare inputs with image\n",
    "    inputs = tokenizer(\n",
    "        image,\n",
    "        input_text,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Generate response with Qwen2.5-VL parameters\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=3000,\n",
    "            temperature=0.8,\n",
    "            min_p=0.1,\n",
    "            use_cache=True,\n",
    "            do_sample=True,\n",
    "        )\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Decode only the generated tokens (excluding input)\n",
    "    generated_tokens = outputs[:, inputs.input_ids.shape[-1]:]\n",
    "    content = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0].strip()\n",
    "\n",
    "    return {\n",
    "        'content': content\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_answer_letter(content):\n",
    "    \"\"\"\n",
    "    Enhanced function to extract an answer letter from a model's output.\n",
    "    It includes patterns for plain text, markdown, and LaTeX formats to ensure\n",
    "    the answer is captured reliably.\n",
    "    Args:\n",
    "        content (str): The model's output content.\n",
    "    Returns:\n",
    "        str: The extracted answer letter (A, B, C, or D), or an empty string if not found.\n",
    "    \"\"\"\n",
    "    # Enhanced list of regex patterns to try, in order of preference\n",
    "    patterns = [\n",
    "        # LaTeX box patterns - FIXED PATTERNS\n",
    "        r\"\\\\boxed\\{([A-D])\\}\",                # Handles '\\boxed{A}' or '$\\boxed{A}$'\n",
    "        r\"\\$\\\\boxed\\{([A-D])\\}\\$\",            # Handles '$\\boxed{A}$'\n",
    "        r\"\\\\boxed\\{\\\\text\\{([A-D])\\}\\}\",      # Handles '\\boxed{\\text{A}}'\n",
    "        r\"\\$\\\\boxed\\{\\\\text\\{([A-D])\\}\\}\\$\",  # Handles '$\\boxed{\\text{A}}$'\n",
    "        r\"The final answer is \\$\\\\boxed\\{([A-D])\\}\\$\",  # 'The final answer is $\\boxed{A}$'\n",
    "        r\"The final answer is \\\\boxed\\{([A-D])\\}\",      # 'The final answer is \\boxed{A}'\n",
    "        r\"The final answer is \\$\\\\boxed\\{(\\d+)\\}\\$\",    # Extract from numeric boxed answers\n",
    "        \n",
    "        # Standard patterns\n",
    "        r\"Final Answer:\\s*([A-D])\\b\",        # Final Answer: A\n",
    "        r\"Final Answer:\\s*\\*\\*([A-D])\\*\\*\",  # Final Answer: **A**\n",
    "        r\"Answer:\\s*([A-D])\\b\",              # Answer: A\n",
    "        r\"Answer:\\s*\\*\\*([A-D])\\*\\*\",        # Answer: **A**\n",
    "        r\"Answer:\\s*\\*([A-D])\\*\",            # Answer: *A*\n",
    "        r\"Answer:\\s*_([A-D])_\",              # Answer: _A_\n",
    "        r\"Answer:\\s*\\(([A-D])\\)\",            # Answer: (A)\n",
    "        r\"Answer:\\s*([A-D])\\.\",              # Answer: A.\n",
    "        \n",
    "        # Sentence-based patterns\n",
    "        r\"The answer is\\s*([A-D])\\b\",        # The answer is A\n",
    "        r\"The correct answer is\\s*([A-D])\\b\", # The correct answer is A\n",
    "        r\"\\b([A-D])\\s*is the correct\",       # A is the correct\n",
    "        \n",
    "        # Choice/option patterns\n",
    "        r\"choice\\s*([A-D])\\b\",               # choice A\n",
    "        r\"option\\s*([A-D])\\b\",               # option A\n",
    "        r\"select\\s*([A-D])\\b\",               # select A\n",
    "        r\"choose\\s*([A-D])\\b\",               # choose A\n",
    "        \n",
    "        # Concluding word patterns\n",
    "        r\"Therefore,?\\s*([A-D])\\b\",          # Therefore, A\n",
    "        r\"Thus,?\\s*([A-D])\\b\",               # Thus, A\n",
    "        r\"Hence,?\\s*([A-D])\\b\",              # Hence, A\n",
    "    ]\n",
    "    \n",
    "    # Try each pattern in the defined order\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, content, re.IGNORECASE)\n",
    "        if match:\n",
    "            captured = match.group(1).upper()\n",
    "            # Handle numeric answers by mapping to choices if needed\n",
    "            if captured.isdigit():\n",
    "                # You might need to implement logic here to map numbers to letters\n",
    "                # based on your specific answer choices\n",
    "                continue\n",
    "            return captured\n",
    "    \n",
    "    # Special handling for boxed numeric answers like \"The final answer is $\\boxed{14}$\"\n",
    "    # Try to match the numeric value with your answer choices\n",
    "    numeric_boxed = re.search(r\"\\\\boxed\\{([0-9.]+)\\}\", content)\n",
    "    if numeric_boxed:\n",
    "        numeric_value = numeric_boxed.group(1)\n",
    "        # You would need to compare this with your actual answer choices\n",
    "        # and return the corresponding letter\n",
    "        # For now, we'll continue to other patterns\n",
    "        pass\n",
    "    \n",
    "    # If no specific pattern matches, look for isolated letters near the end\n",
    "    lines = content.strip().split('\\n')\n",
    "    for line in reversed(lines[-10:]):  # Check the last 10 lines\n",
    "        line = line.strip()\n",
    "        if line in ['A', 'B', 'C', 'D']:\n",
    "            return line\n",
    "        # Check if a line contains only one of the possible answer letters\n",
    "        letters_found = re.findall(r'\\b([A-D])\\b', line)\n",
    "        if len(letters_found) == 1:\n",
    "            return letters_found[0].upper()\n",
    "    \n",
    "    # As a last resort, find any occurrence of A, B, C, or D in the content\n",
    "    all_letters = re.findall(r'\\b([A-D])\\b', content)\n",
    "    if all_letters:\n",
    "        # Return the last one found, as it's most likely the final answer\n",
    "        return all_letters[-1].upper()\n",
    "    \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def validate_and_retry_if_needed(image_path, question, choices, max_retries=3):\n",
    "    \"\"\"\n",
    "    Try to get a valid answer letter, with retries if needed.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        result = solve_geometry_problem_with_image(image_path, question, choices)\n",
    "        content = result['content']\n",
    "        answer_letter = extract_answer_letter(content)\n",
    "        \n",
    "        if answer_letter in ['A', 'B', 'C', 'D']:\n",
    "            return content, answer_letter\n",
    "        \n",
    "        print(f\"Attempt {attempt + 1} failed to extract valid answer letter\")\n",
    "    \n",
    "    # If all attempts fail, try one more time with a very direct prompt\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        direct_prompt = f\"\"\"Look at this geometry problem image and answer the question.\n",
    "\n",
    "QUESTION: {question}\n",
    "ANSWER CHOICES: {choices}\n",
    "\n",
    "⚠️ CRITICAL OUTPUT FORMAT REQUIREMENT ⚠️\n",
    "YOU MUST END YOUR RESPONSE WITH EXACTLY ONE OF THESE FOUR LINES:\n",
    "Final Answer: A\n",
    "Final Answer: B\n",
    "Final Answer: C\n",
    "Final Answer: D\n",
    "\n",
    "❌ ABSOLUTELY FORBIDDEN - DO NOT USE:\n",
    "- \"The final answer is $\\\\boxed{{14}}$\"\n",
    "- \"The final answer is $\\\\boxed{{A}}$\"\n",
    "- \"$\\\\boxed{{A}}$\"\n",
    "- \"\\\\boxed{{A}}\"\n",
    "- \"(A)\"\n",
    "- \"A is correct.\"\n",
    "- \"Final Answer: The answer is A\"\n",
    "- Any LaTeX formatting\n",
    "- Any mathematical notation\n",
    "- Any additional text after the letter\n",
    "\n",
    "✅ REQUIRED FORMAT EXAMPLES:\n",
    "If you determine the answer is choice A: \"Final Answer: A\"\n",
    "If you determine the answer is choice B: \"Final Answer: B\"\n",
    "If you determine the answer is choice C: \"Final Answer: C\"\n",
    "If you determine the answer is choice D: \"Final Answer: D\"\n",
    "\n",
    "IMPORTANT: Your response must end with exactly \"Final Answer: [SINGLE LETTER]\" - nothing else on that line. Do not include any boxed notation, LaTeX, or mathematical formatting in your final line.\n",
    "\n",
    "Begin your analysis now and remember to end with the exact required format.\n",
    "\"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\"},\n",
    "                    {\"type\": \"text\", \"text\": direct_prompt}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "        inputs = tokenizer(image, input_text, add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, max_new_tokens=3000, temperature=0.8, min_p=0.1, use_cache=True, do_sample=True)\n",
    "        \n",
    "        generated_tokens = outputs[:, inputs.input_ids.shape[-1]:]\n",
    "        final_content = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0].strip()\n",
    "        final_letter = extract_answer_letter(final_content)\n",
    "        \n",
    "        return final_content, final_letter if final_letter in ['A', 'B', 'C', 'D'] else 'A'  # Default to A if still fails\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in final retry: {e}\")\n",
    "        return \"Error occurred\", 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Input directories\n",
    "    image_dir = \"image\"  # Changed from predicates_dir to image_dir\n",
    "    questions_dir = \"/question\"\n",
    "    choices_dir = \"choices\"\n",
    "    \n",
    "    # Output directories\n",
    "    reasoning_output_dir = \"/kaggle/working/reasoning_output\"\n",
    "    answer_literal_dir = \"/kaggle/working/answer_literal_qwen2_5_vl\"  # Updated name\n",
    "    os.makedirs(reasoning_output_dir, exist_ok=True)\n",
    "    os.makedirs(answer_literal_dir, exist_ok=True)\n",
    "    \n",
    "    # Iterate over problem numbers\n",
    "    for num_str in tqdm(range(2401, 3002)):        \n",
    "        # Paths to input files\n",
    "        image_path = os.path.join(image_dir, f\"{num_str}.png\")  # Changed to .png extension\n",
    "        ques_path = os.path.join(questions_dir, f\"{num_str}.txt\")\n",
    "        choice_path = os.path.join(choices_dir, f\"{num_str}.txt\")\n",
    "        \n",
    "        # Check if all required files exist\n",
    "        if not all(os.path.exists(path) for path in [image_path, ques_path, choice_path]):\n",
    "            print(f\"Skipping problem {num_str}: Missing input files\")\n",
    "            continue\n",
    "        \n",
    "        # Read inputs\n",
    "        try:\n",
    "            with open(ques_path, \"r\") as f:\n",
    "                question = f.read().strip()\n",
    "            with open(choice_path, \"r\") as f:\n",
    "                choices = f.read().strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading files for problem {num_str}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Solve with validation and retry mechanism\n",
    "        simple_content, answer_letter = validate_and_retry_if_needed(image_path, question, choices)\n",
    "        \n",
    "        # Build the reasoning file content\n",
    "        reasoning_lines = []\n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        reasoning_lines.append(\"PROBLEM DETAILS:\")\n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        reasoning_lines.append(f\"IMAGE: {image_path}\")  # Changed from PREDICATES to IMAGE\n",
    "        reasoning_lines.append(\"\")\n",
    "        reasoning_lines.append(f\"QUESTION:\\n{question}\")\n",
    "        reasoning_lines.append(\"\")\n",
    "        reasoning_lines.append(f\"CHOICES:\\n{choices}\")\n",
    "        reasoning_lines.append(\"\")\n",
    "        \n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        reasoning_lines.append(\"QWEN2.5-VL MODEL RESPONSE:\")  # Updated model name\n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        reasoning_lines.append(simple_content)\n",
    "        reasoning_lines.append(\"\")\n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        reasoning_lines.append(f\"EXTRACTED ANSWER: {answer_letter}\")\n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        \n",
    "        reasoning_output = \"\\n\".join(reasoning_lines)\n",
    "        \n",
    "        # Write reasoning output to file\n",
    "        reasoning_out_path = os.path.join(reasoning_output_dir, f\"{num_str}.txt\")\n",
    "        with open(reasoning_out_path, \"w\") as f:\n",
    "            f.write(reasoning_output)\n",
    "        \n",
    "        # Validate answer letter\n",
    "        if not answer_letter or answer_letter not in ['A', 'B', 'C', 'D']:\n",
    "            print(f\"Warning: Invalid answer letter '{answer_letter}' for problem {num_str}\")\n",
    "            print(f\"Content: {simple_content[:200]}...\")\n",
    "            # Force a default answer rather than empty\n",
    "            answer_letter = 'A'  # Default fallback\n",
    "        \n",
    "        # Write just the answer letter to a separate file\n",
    "        letter_out_path = os.path.join(answer_literal_dir, f\"{num_str}.txt\")\n",
    "        with open(letter_out_path, \"w\") as f:\n",
    "            f.write(answer_letter)\n",
    "        \n",
    "        print(f\"Problem {num_str}: Answer = {answer_letter}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7590724,
     "sourceId": 12382909,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
