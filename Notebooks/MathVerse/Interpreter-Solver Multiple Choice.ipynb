{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install unsloth\n",
    "# Also get the latest nightly Unsloth if you want!\n",
    "# !pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel  # FastVisionModel for LLMs\n",
    "import torch\n",
    "max_seq_length = 2048  # Choose any! We auto support RoPE Scaling internally!\n",
    "load_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen3-8B-unsloth-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()  # set to eval mode\n",
    "\n",
    "def solve_geometry_problem(predicates, question, choices, enable_thinking=True):\n",
    "    \"\"\"\n",
    "    Solve geometry problem using Qwen3 Model with step-by-step reasoning\n",
    "\n",
    "    Args:\n",
    "        predicates (str): Geometric constraints from image\n",
    "        question (str): Question to solve\n",
    "        choices (str): Multiple choice options (A, B, C, D)\n",
    "        enable_thinking (bool): Enable thinking mode for step-by-step reasoning\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains 'thinking_content' and 'content'\n",
    "    \"\"\"\n",
    "\n",
    "    # Enhanced prompt to force choice selection\n",
    "    prompt = f\"\"\"You are an expert AI mathematician specializing in geometry. Your task is to solve the following geometric problem using the provided predicates through systematic reasoning and theorem application.\n",
    "\n",
    "GIVEN GEOMETRIC PREDICATES:\n",
    "{predicates}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "ANSWER CHOICES:\n",
    "{choices}\n",
    "\n",
    "YOUR TASK:\n",
    "Provide a complete step-by-step solution following the structured approach below, then select the correct answer choice.\n",
    "\n",
    "STEP-BY-STEP SOLUTION PROCESS:\n",
    "\n",
    "STEP 1: PREDICATE ANALYSIS AND SETUP\n",
    "- Parse and categorize the given predicates into:\n",
    "  * Geometric shapes (points, lines, circles, triangles, etc.)\n",
    "  * Measurements and equalities (lengths, angles, areas)\n",
    "  * Relationships (perpendicular, parallel, congruent, etc.)\n",
    "  * Positioning (points on lines/circles, intersections, etc.)\n",
    "- Identify what specific value or measurement the question is asking for\n",
    "- Note any special geometric constructions or theorems that might apply\n",
    "\n",
    "STEP 2: CONSTRAINT SYNTHESIS\n",
    "- Combine related predicates to understand the complete geometric picture\n",
    "- Identify key relationships that will be useful for solving\n",
    "- Look for:\n",
    "  * Equal lengths or angles that can be substituted\n",
    "  * Perpendicular relationships that create right triangles\n",
    "  * Circle properties (radii, chords, central/inscribed angles)\n",
    "  * Congruent or similar triangles\n",
    "  * Theorem applications (Pythagorean, inscribed angle, etc.)\n",
    "\n",
    "STEP 3: SOLUTION STRATEGY\n",
    "- Based on the predicates and question, determine the most direct solution path\n",
    "- Identify which geometric theorems, properties, or formulas to apply\n",
    "- Plan the sequence of logical steps needed to reach the answer\n",
    "\n",
    "STEP 4: MATHEMATICAL DERIVATION\n",
    "- Execute your solution strategy step by step\n",
    "- Show all calculations clearly with proper mathematical notation\n",
    "- Apply geometric theorems and properties systematically\n",
    "- Use the relationships established in the predicates\n",
    "- Substitute known values and solve for unknowns\n",
    "\n",
    "STEP 5: VERIFICATION AND ANSWER SELECTION\n",
    "- Verify your calculated result makes geometric sense\n",
    "- Compare your result with the provided answer choices\n",
    "- Select the choice that best matches your calculated answer\n",
    "- If no exact match, select the closest reasonable option\n",
    "\n",
    "GEOMETRIC REASONING GUIDANCE:\n",
    "- Consider all relevant geometric theorems and properties\n",
    "- Apply circle, triangle, quadrilateral, and angle theorems as appropriate\n",
    "- Look for relationships between shapes, measurements, and positions\n",
    "- Use both basic and advanced geometric principles as needed\n",
    "\n",
    "PREDICATE USAGE GUIDANCE:\n",
    "- Interpret predicates based on their geometric meaning and context\n",
    "- Combine multiple predicates to understand complex relationships\n",
    "- Consider both direct and derived information from predicate combinations\n",
    "\n",
    "CRITICAL INSTRUCTIONS:\n",
    "1. **USE THE PREDICATES SYSTEMATICALLY** - Every predicate provides important information\n",
    "2. **APPLY RELEVANT GEOMETRIC KNOWLEDGE** - Use any geometric theorems, properties, or principles that help solve the problem\n",
    "3. **REASON FLEXIBLY** - Adapt your approach based on the specific problem and predicates\n",
    "4. **SHOW ALL WORK** - Make your reasoning clear and mathematical\n",
    "5. **BE PRECISE** - Use exact values when possible, approximate only when necessary\n",
    "\n",
    "⚠️ CRITICAL OUTPUT FORMAT REQUIREMENT ⚠️\n",
    "YOU MUST END YOUR RESPONSE WITH EXACTLY ONE OF THESE FOUR LINES:\n",
    "Final Answer: A\n",
    "Final Answer: B\n",
    "Final Answer: C\n",
    "Final Answer: D\n",
    "\n",
    "❌ ABSOLUTELY FORBIDDEN - DO NOT USE:\n",
    "- \"The final answer is $\\\\boxed{{14}}$\"\n",
    "- \"The final answer is $\\\\boxed{{A}}$\"\n",
    "- \"$\\\\boxed{{A}}$\"\n",
    "- \"\\\\boxed{{A}}\"\n",
    "- \"(A)\"\n",
    "- \"A is correct.\"\n",
    "- \"Final Answer: The answer is A\"\n",
    "- Any LaTeX formatting\n",
    "- Any mathematical notation\n",
    "- Any additional text after the letter\n",
    "\n",
    "✅ REQUIRED FORMAT EXAMPLES:\n",
    "If you determine the answer is choice A: \"Final Answer: A\"\n",
    "If you determine the answer is choice B: \"Final Answer: B\"\n",
    "If you determine the answer is choice C: \"Final Answer: C\"\n",
    "If you determine the answer is choice D: \"Final Answer: D\"\n",
    "\n",
    "IMPORTANT: Your response must end with exactly \"Final Answer: [SINGLE LETTER]\" - nothing else on that line. Do not include any boxed notation, LaTeX, or mathematical formatting in your final line.\n",
    "\n",
    "Begin your analysis now and remember to end with the exact required format.\n",
    "\"\"\"\n",
    "\n",
    "    # Create messages\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    # Apply chat template with thinking mode\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=enable_thinking\n",
    "    )\n",
    "\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Generate response with official Qwen3 parameters\n",
    "        if enable_thinking:\n",
    "            # For thinking mode: Temperature=0.6, TopP=0.95, TopK=20, MinP=0\n",
    "            generated_ids = model.generate(\n",
    "                **model_inputs,\n",
    "                max_new_tokens=15000,  # Adjusted from 15768 to 4000\n",
    "                temperature=0.6,\n",
    "                top_p=0.95,\n",
    "                top_k=20,\n",
    "                min_p=0.0,\n",
    "                do_sample=True,\n",
    "                repetition_penalty=1.1  # To reduce repetitions\n",
    "            )\n",
    "        else:\n",
    "            # For non-thinking mode: Temperature=0.7, TopP=0.8, TopK=20, MinP=0\n",
    "            generated_ids = model.generate(\n",
    "                **model_inputs,\n",
    "                max_new_tokens=15000,  # Adjusted from 15768 to 4000\n",
    "                temperature=0.7,\n",
    "                top_p=0.8,\n",
    "                top_k=20,\n",
    "                min_p=0.0,\n",
    "                do_sample=True,\n",
    "                repetition_penalty=1.1  # To reduce repetitions\n",
    "            )\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\n",
    "    # Improved thinking content parsing\n",
    "    if enable_thinking:\n",
    "        # First decode the entire output\n",
    "        full_output = tokenizer.decode(output_ids, skip_special_tokens=True).strip(\"\\n\")\n",
    "        \n",
    "        # Try to find thinking tags in the decoded text\n",
    "        if \"<think>\" in full_output and \"</think>\" in full_output:\n",
    "            # Split by thinking tags\n",
    "            parts = full_output.split(\"<think>\", 1)\n",
    "            if len(parts) > 1:\n",
    "                thinking_part = parts[1].split(\"</think>\", 1)\n",
    "                if len(thinking_part) > 1:\n",
    "                    thinking_content = thinking_part[0].strip()\n",
    "                    content = thinking_part[1].strip()\n",
    "                else:\n",
    "                    # No closing think tag found\n",
    "                    thinking_content = thinking_part[0].strip()\n",
    "                    content = \"\"\n",
    "            else:\n",
    "                thinking_content = \"\"\n",
    "                content = full_output\n",
    "        else:\n",
    "            # No thinking tags found, try token-based parsing as fallback\n",
    "            try:\n",
    "                # Get the token ID for </think>\n",
    "                think_end_token = tokenizer.convert_tokens_to_ids(\"</think>\")\n",
    "                if think_end_token in output_ids:\n",
    "                    index = len(output_ids) - output_ids[::-1].index(think_end_token)\n",
    "                    thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "                    content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "                else:\n",
    "                    # No thinking token found, treat entire output as content\n",
    "                    thinking_content = \"\"\n",
    "                    content = full_output\n",
    "            except (ValueError, KeyError):\n",
    "                # Fallback: treat entire output as content\n",
    "                thinking_content = \"\"\n",
    "                content = full_output\n",
    "    else:\n",
    "        # No thinking mode, entire output is content\n",
    "        thinking_content = \"\"\n",
    "        content = tokenizer.decode(output_ids, skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "    return {\n",
    "        'thinking_content': thinking_content,\n",
    "        'content': content\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_answer_letter(content):\n",
    "    \"\"\"\n",
    "    Enhanced function to extract an answer letter from a model's output.\n",
    "    It includes patterns for plain text, markdown, and LaTeX formats to ensure\n",
    "    the answer is captured reliably.\n",
    "    Args:\n",
    "        content (str): The model's output content.\n",
    "    Returns:\n",
    "        str: The extracted answer letter (A, B, C, or D), or an empty string if not found.\n",
    "    \"\"\"\n",
    "    # Enhanced list of regex patterns to try, in order of preference\n",
    "    patterns = [\n",
    "        # LaTeX box patterns - FIXED PATTERNS\n",
    "        r\"\\\\boxed\\{([A-D])\\}\",                # Handles '\\boxed{A}' or '$\\boxed{A}$'\n",
    "        r\"\\$\\\\boxed\\{([A-D])\\}\\$\",            # Handles '$\\boxed{A}$'\n",
    "        r\"\\\\boxed\\{\\\\text\\{([A-D])\\}\\}\",      # Handles '\\boxed{\\text{A}}'\n",
    "        r\"\\$\\\\boxed\\{\\\\text\\{([A-D])\\}\\}\\$\",  # Handles '$\\boxed{\\text{A}}$'\n",
    "        r\"The final answer is \\$\\\\boxed\\{([A-D])\\}\\$\",  # 'The final answer is $\\boxed{A}$'\n",
    "        r\"The final answer is \\\\boxed\\{([A-D])\\}\",      # 'The final answer is \\boxed{A}'\n",
    "        r\"The final answer is \\$\\\\boxed\\{(\\d+)\\}\\$\",    # Extract from numeric boxed answers\n",
    "        \n",
    "        # Standard patterns\n",
    "        r\"Final Answer:\\s*([A-D])\\b\",        # Final Answer: A\n",
    "        r\"Final Answer:\\s*\\*\\*([A-D])\\*\\*\",  # Final Answer: **A**\n",
    "        r\"Answer:\\s*([A-D])\\b\",              # Answer: A\n",
    "        r\"Answer:\\s*\\*\\*([A-D])\\*\\*\",        # Answer: **A**\n",
    "        r\"Answer:\\s*\\*([A-D])\\*\",            # Answer: *A*\n",
    "        r\"Answer:\\s*_([A-D])_\",              # Answer: _A_\n",
    "        r\"Answer:\\s*\\(([A-D])\\)\",            # Answer: (A)\n",
    "        r\"Answer:\\s*([A-D])\\.\",              # Answer: A.\n",
    "        \n",
    "        # Sentence-based patterns\n",
    "        r\"The answer is\\s*([A-D])\\b\",        # The answer is A\n",
    "        r\"The correct answer is\\s*([A-D])\\b\", # The correct answer is A\n",
    "        r\"\\b([A-D])\\s*is the correct\",       # A is the correct\n",
    "        \n",
    "        # Choice/option patterns\n",
    "        r\"choice\\s*([A-D])\\b\",               # choice A\n",
    "        r\"option\\s*([A-D])\\b\",               # option A\n",
    "        r\"select\\s*([A-D])\\b\",               # select A\n",
    "        r\"choose\\s*([A-D])\\b\",               # choose A\n",
    "        \n",
    "        # Concluding word patterns\n",
    "        r\"Therefore,?\\s*([A-D])\\b\",          # Therefore, A\n",
    "        r\"Thus,?\\s*([A-D])\\b\",               # Thus, A\n",
    "        r\"Hence,?\\s*([A-D])\\b\",              # Hence, A\n",
    "    ]\n",
    "    \n",
    "    # Try each pattern in the defined order\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, content, re.IGNORECASE)\n",
    "        if match:\n",
    "            captured = match.group(1).upper()\n",
    "            # Handle numeric answers by mapping to choices if needed\n",
    "            if captured.isdigit():\n",
    "                # You might need to implement logic here to map numbers to letters\n",
    "                # based on your specific answer choices\n",
    "                continue\n",
    "            return captured\n",
    "    \n",
    "    # Special handling for boxed numeric answers like \"The final answer is $\\boxed{14}$\"\n",
    "    # Try to match the numeric value with your answer choices\n",
    "    numeric_boxed = re.search(r\"\\\\boxed\\{([0-9.]+)\\}\", content)\n",
    "    if numeric_boxed:\n",
    "        numeric_value = numeric_boxed.group(1)\n",
    "        # You would need to compare this with your actual answer choices\n",
    "        # and return the corresponding letter\n",
    "        # For now, we'll continue to other patterns\n",
    "        pass\n",
    "    \n",
    "    # If no specific pattern matches, look for isolated letters near the end\n",
    "    lines = content.strip().split('\\n')\n",
    "    for line in reversed(lines[-10:]):  # Check the last 10 lines\n",
    "        line = line.strip()\n",
    "        if line in ['A', 'B', 'C', 'D']:\n",
    "            return line\n",
    "        # Check if a line contains only one of the possible answer letters\n",
    "        letters_found = re.findall(r'\\b([A-D])\\b', line)\n",
    "        if len(letters_found) == 1:\n",
    "            return letters_found[0].upper()\n",
    "    \n",
    "    # As a last resort, find any occurrence of A, B, C, or D in the content\n",
    "    all_letters = re.findall(r'\\b([A-D])\\b', content)\n",
    "    if all_letters:\n",
    "        # Return the last one found, as it's most likely the final answer\n",
    "        return all_letters[-1].upper()\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "# Additional helper function to map numeric answers to letters if needed\n",
    "def map_numeric_to_letter(numeric_value, answer_choices):\n",
    "    \"\"\"\n",
    "    Map a numeric value to the corresponding letter choice.\n",
    "    Args:\n",
    "        numeric_value (str): The numeric value extracted\n",
    "        answer_choices (dict): Dictionary mapping letters to values\n",
    "    Returns:\n",
    "        str: The corresponding letter, or empty string if no match\n",
    "    \"\"\"\n",
    "    try:\n",
    "        num_val = float(numeric_value)\n",
    "        for letter, choice_value in answer_choices.items():\n",
    "            if isinstance(choice_value, (int, float)) and abs(float(choice_value) - num_val) < 0.01:\n",
    "                return letter\n",
    "    except (ValueError, TypeError):\n",
    "        pass\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def validate_and_retry_if_needed(predicates, question, choices, max_retries=3):\n",
    "    \"\"\"\n",
    "    Try to get a valid answer letter, with retries if needed.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        result = solve_geometry_problem(predicates, question, choices, enable_thinking=True)\n",
    "        content = result['content']\n",
    "        thinking_content = result['thinking_content']\n",
    "        answer_letter = extract_answer_letter(content)\n",
    "        \n",
    "        if answer_letter in ['A', 'B', 'C', 'D']:\n",
    "            return content, thinking_content, answer_letter\n",
    "        \n",
    "        print(f\"Attempt {attempt + 1} failed to extract valid answer letter\")\n",
    "    \n",
    "    # If all attempts fail, try one more time with a very direct prompt\n",
    "    direct_prompt = f\"\"\"Given the following geometry problem, you must choose exactly one answer from A, B, C, or D.\n",
    "\n",
    "CONSTRAINTS: {predicates}\n",
    "QUESTION: {question}\n",
    "CHOICES: {choices}\n",
    "\n",
    "⚠️ CRITICAL OUTPUT FORMAT REQUIREMENT ⚠️\n",
    "YOU MUST END YOUR RESPONSE WITH EXACTLY ONE OF THESE FOUR LINES:\n",
    "Final Answer: A\n",
    "Final Answer: B\n",
    "Final Answer: C\n",
    "Final Answer: D\n",
    "\n",
    "❌ ABSOLUTELY FORBIDDEN - DO NOT USE:\n",
    "- \"The final answer is $\\\\boxed{{14}}$\"\n",
    "- \"The final answer is $\\\\boxed{{A}}$\"\n",
    "- \"$\\\\boxed{{A}}$\"\n",
    "- \"\\\\boxed{{A}}\"\n",
    "- \"(A)\"\n",
    "- \"A is correct.\"\n",
    "- \"Final Answer: The answer is A\"\n",
    "- Any LaTeX formatting\n",
    "- Any mathematical notation\n",
    "- Any additional text after the letter\n",
    "\n",
    "✅ REQUIRED FORMAT EXAMPLES:\n",
    "If you determine the answer is choice A: \"Final Answer: A\"\n",
    "If you determine the answer is choice B: \"Final Answer: B\"\n",
    "If you determine the answer is choice C: \"Final Answer: C\"\n",
    "If you determine the answer is choice D: \"Final Answer: D\"\n",
    "\n",
    "IMPORTANT: Your response must end with exactly \"Final Answer: [SINGLE LETTER]\" - nothing else on that line. Do not include any boxed notation, LaTeX, or mathematical formatting in your final line.\n",
    "\n",
    "Begin your analysis now and remember to end with the exact required format.\n",
    "\"\"\"\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": direct_prompt}]\n",
    "    text = tokenizer.apply_chat_template(messages,\n",
    "                                         tokenize=False, \n",
    "                                         add_generation_prompt=True, \n",
    "                                         enable_thinking=True)\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Use thinking mode parameters for the final retry\n",
    "        generated_ids = model.generate(\n",
    "            **model_inputs, \n",
    "            max_new_tokens=10000, \n",
    "            temperature=0.6,\n",
    "            top_p=0.95,\n",
    "            top_k=20,\n",
    "            min_p=0.0,\n",
    "            do_sample=True,\n",
    "            repetition_penalty=1.1\n",
    "        )\n",
    "    \n",
    "    output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "    final_content = tokenizer.decode(output_ids, skip_special_tokens=True).strip()\n",
    "    final_letter = extract_answer_letter(final_content)\n",
    "    \n",
    "    return final_content, \"\", final_letter if final_letter in ['A', 'B', 'C', 'D'] else 'A'  # Default to A if still fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Input directories\n",
    "    predicates_dir = \"predicates_output\"\n",
    "    questions_dir = \"questions\"\n",
    "    choices_dir = \"choices\"\n",
    "    \n",
    "    # Output directories\n",
    "    reasoning_output_dir = \"/kaggle/working/reasoning_output\"\n",
    "    answer_literal_dir = \"/kaggle/working/answer_literal_qwen\"\n",
    "    os.makedirs(reasoning_output_dir, exist_ok=True)\n",
    "    os.makedirs(answer_literal_dir, exist_ok=True)\n",
    "    \n",
    "    # Iterate over problem numbers 2401 to 3001 (inclusive)\n",
    "    # for num in tqdm(range(2450, 2500)):  # Fixed the range issue\n",
    "    for num in tqdm(range(50, 100)):\n",
    "        \n",
    "        num_str = str(num).zfill(3)\n",
    "        \n",
    "        # Paths to input files\n",
    "        pred_path = os.path.join(predicates_dir, f\"{num_str}.txt\")\n",
    "        ques_path = os.path.join(questions_dir, f\"{num_str}.txt\")\n",
    "        choice_path = os.path.join(choices_dir, f\"{num_str}.txt\")\n",
    "        \n",
    "        # Check if all required files exist\n",
    "        if not all(os.path.exists(path) for path in [pred_path, ques_path, choice_path]):\n",
    "            print(f\"Skipping problem {num_str}: Missing input files\")\n",
    "            continue\n",
    "        \n",
    "        # Read inputs\n",
    "        try:\n",
    "            with open(pred_path, \"r\") as f:\n",
    "                predicates = f.read().strip()\n",
    "            with open(ques_path, \"r\") as f:\n",
    "                question = f.read().strip()\n",
    "            with open(choice_path, \"r\") as f:\n",
    "                choices = f.read().strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading files for problem {num_str}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Solve with validation and retry mechanism\n",
    "        simple_content, thinking_content, answer_letter = validate_and_retry_if_needed(predicates, question, choices)\n",
    "        \n",
    "        # Build the reasoning file content with thinking content included\n",
    "        reasoning_lines = []\n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        reasoning_lines.append(\"PROBLEM DETAILS:\")\n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        reasoning_lines.append(f\"PREDICATES:\\n{predicates}\")\n",
    "        reasoning_lines.append(\"\")\n",
    "        reasoning_lines.append(f\"QUESTION:\\n{question}\")\n",
    "        reasoning_lines.append(\"\")\n",
    "        reasoning_lines.append(f\"CHOICES:\\n{choices}\")\n",
    "        reasoning_lines.append(\"\")\n",
    "        \n",
    "        # Add thinking content if available\n",
    "        if thinking_content.strip():\n",
    "            reasoning_lines.append(\"=\" * 100)\n",
    "            reasoning_lines.append(\"MODEL'S INTERNAL REASONING (THINKING MODE):\")\n",
    "            reasoning_lines.append(\"=\" * 100)\n",
    "            reasoning_lines.append(thinking_content)\n",
    "            reasoning_lines.append(\"\")\n",
    "        \n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        reasoning_lines.append(\"FINAL RESPONSE:\")\n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        reasoning_lines.append(simple_content)\n",
    "        reasoning_lines.append(\"\")\n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        reasoning_lines.append(f\"EXTRACTED ANSWER: {answer_letter}\")\n",
    "        reasoning_lines.append(\"=\" * 100)\n",
    "        \n",
    "        reasoning_output = \"\\n\".join(reasoning_lines)\n",
    "        \n",
    "        # Write reasoning output to file\n",
    "        reasoning_out_path = os.path.join(reasoning_output_dir, f\"{num_str}.txt\")\n",
    "        with open(reasoning_out_path, \"w\") as f:\n",
    "            f.write(reasoning_output)\n",
    "        \n",
    "        # Validate answer letter\n",
    "        if not answer_letter or answer_letter not in ['A', 'B', 'C', 'D']:\n",
    "            print(f\"Warning: Invalid answer letter '{answer_letter}' for problem {num_str}\")\n",
    "            print(f\"Content: {simple_content[:200]}...\")\n",
    "            # Force a default answer rather than empty\n",
    "            answer_letter = 'A'  # Default fallback\n",
    "        \n",
    "        # Write just the answer letter to a separate file\n",
    "        letter_out_path = os.path.join(answer_literal_dir, f\"{num_str}.txt\")\n",
    "        with open(letter_out_path, \"w\") as f:\n",
    "            f.write(answer_letter)\n",
    "        \n",
    "        print(f\"Problem {num_str}: Answer = {answer_letter}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7590724,
     "sourceId": 12305265,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
