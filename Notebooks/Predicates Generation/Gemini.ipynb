{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-14T06:32:46.571368Z",
     "iopub.status.busy": "2025-07-14T06:32:46.570558Z",
     "iopub.status.idle": "2025-07-14T06:33:20.615881Z",
     "shell.execute_reply": "2025-07-14T06:33:20.614872Z",
     "shell.execute_reply.started": "2025-07-14T06:32:46.571332Z"
    },
    "papermill": {
     "duration": 16.416146,
     "end_time": "2025-06-18T08:12:00.846752",
     "exception": false,
     "start_time": "2025-06-18T08:11:44.430606",
     "status": "completed"
    },
    "scrolled": true,
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012594,
     "end_time": "2025-06-18T08:12:00.875303",
     "exception": false,
     "start_time": "2025-06-18T08:12:00.862709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predicates Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:33:20.618271Z",
     "iopub.status.busy": "2025-07-14T06:33:20.617716Z",
     "iopub.status.idle": "2025-07-14T06:33:22.332021Z",
     "shell.execute_reply": "2025-07-14T06:33:22.331150Z",
     "shell.execute_reply.started": "2025-07-14T06:33:20.618246Z"
    },
    "papermill": {
     "duration": 1.594338,
     "end_time": "2025-06-18T08:12:02.48155",
     "exception": false,
     "start_time": "2025-06-18T08:12:00.887212",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import queue\n",
    "import logging\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:33:22.333173Z",
     "iopub.status.busy": "2025-07-14T06:33:22.332794Z",
     "iopub.status.idle": "2025-07-14T06:33:22.338894Z",
     "shell.execute_reply": "2025-07-14T06:33:22.338108Z",
     "shell.execute_reply.started": "2025-07-14T06:33:22.333154Z"
    },
    "papermill": {
     "duration": 0.021021,
     "end_time": "2025-06-18T08:12:02.514239",
     "exception": false,
     "start_time": "2025-06-18T08:12:02.493218",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ensure the output folder exists\n",
    "os.makedirs(\"content\", exist_ok=True)\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"gemini_predicate_generator.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:33:22.340102Z",
     "iopub.status.busy": "2025-07-14T06:33:22.339831Z",
     "iopub.status.idle": "2025-07-14T06:33:22.362548Z",
     "shell.execute_reply": "2025-07-14T06:33:22.361758Z",
     "shell.execute_reply.started": "2025-07-14T06:33:22.340074Z"
    },
    "papermill": {
     "duration": 0.034179,
     "end_time": "2025-06-18T08:12:02.560603",
     "exception": false,
     "start_time": "2025-06-18T08:12:02.526424",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GeminiVisionApiManager:\n",
    "    \"\"\"\n",
    "    Manages multiple Gemini API keys with rotation and rate limiting for vision tasks.\n",
    "    Handles file uploads and content generation with automatic key switching.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, api_keys, calls_per_day=200, rate_limit_delay=4):\n",
    "        \"\"\"\n",
    "        Initialize the API manager with multiple API keys.\n",
    "\n",
    "        Args:\n",
    "            api_keys (list): List of Gemini API keys.\n",
    "            calls_per_day (int): Maximum number of calls allowed per key per day.\n",
    "            rate_limit_delay (int): Seconds to wait between API calls (4 seconds for 15 RPM).\n",
    "        \"\"\"\n",
    "        self.api_keys = deque(api_keys)\n",
    "        self.calls_per_day = calls_per_day\n",
    "        self.rate_limit_delay = rate_limit_delay\n",
    "\n",
    "        # Track usage for each key\n",
    "        self.usage_count = {key: 0 for key in api_keys}\n",
    "        self.current_key = self.api_keys[0]\n",
    "        self.client = genai.Client(api_key=self.current_key)\n",
    "\n",
    "        # Set up a queue for API calls\n",
    "        self.call_queue = queue.Queue()\n",
    "        self.worker_thread = threading.Thread(target=self._process_queue)\n",
    "        self.worker_thread.daemon = True\n",
    "        self.worker_thread.start()\n",
    "\n",
    "        # Cache for uploaded files to avoid re-uploading\n",
    "        self.file_cache = {}\n",
    "\n",
    "        logging.info(f\"Vision API Manager initialized with {len(api_keys)} keys\")\n",
    "\n",
    "    def _rotate_key(self):\n",
    "        \"\"\"Rotate to the next available API key.\"\"\"\n",
    "        self.api_keys.rotate(1)\n",
    "        self.current_key = self.api_keys[0]\n",
    "        self.client = genai.Client(api_key=self.current_key)\n",
    "        # Clear file cache when rotating keys as files are key-specific\n",
    "        self.file_cache.clear()\n",
    "        logging.info(f\"Rotated to new API key (usage: {self.usage_count[self.current_key]})\")\n",
    "\n",
    "    def _find_available_key(self):\n",
    "        \"\"\"Find an API key that hasn't reached the daily limit.\"\"\"\n",
    "        initial_key = self.current_key\n",
    "\n",
    "        if self.usage_count[self.current_key] < self.calls_per_day:\n",
    "            return True\n",
    "\n",
    "        for _ in range(len(self.api_keys)):\n",
    "            self._rotate_key()\n",
    "            if self.usage_count[self.current_key] < self.calls_per_day:\n",
    "                return True\n",
    "            if self.current_key == initial_key:\n",
    "                return False\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _process_queue(self):\n",
    "        \"\"\"Process the queue of API calls.\"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                task_type, args, kwargs, result_queue = self.call_queue.get()\n",
    "                \n",
    "                if not self._find_available_key():\n",
    "                    result_queue.put({\"error\": \"All API keys have reached their daily limit\"})\n",
    "                    self.call_queue.task_done()\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    if task_type == \"upload\":\n",
    "                        response = self.client.files.upload(**kwargs)\n",
    "                        result_queue.put({\"response\": response})\n",
    "                    elif task_type == \"generate\":\n",
    "                        response = self.client.models.generate_content(*args, **kwargs)\n",
    "                        result_queue.put({\"response\": response})\n",
    "                    \n",
    "                    self.usage_count[self.current_key] += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    if \"quota\" in str(e).lower() or \"rate limit\" in str(e).lower():\n",
    "                        self.usage_count[self.current_key] = self.calls_per_day\n",
    "                        logging.warning(f\"API key reached rate limit: {str(e)}\")\n",
    "                        result_queue.put({\"error\": f\"Rate limit: {str(e)}\"})\n",
    "                    else:\n",
    "                        logging.error(f\"API call error: {str(e)}\")\n",
    "                        result_queue.put({\"error\": str(e)})\n",
    "                \n",
    "                time.sleep(self.rate_limit_delay)\n",
    "                self.call_queue.task_done()\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Queue processing error: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    def upload_file(self, file_path):\n",
    "        \"\"\"\n",
    "        Upload a file to Gemini, with caching to avoid re-uploads.\n",
    "        \n",
    "        Args:\n",
    "            file_path (str): Path to the file to upload\n",
    "            \n",
    "        Returns:\n",
    "            The uploaded file object\n",
    "        \"\"\"\n",
    "        # Use current key + file path as cache key\n",
    "        cache_key = f\"{self.current_key}:{file_path}\"\n",
    "        \n",
    "        if cache_key in self.file_cache:\n",
    "            return self.file_cache[cache_key]\n",
    "        \n",
    "        result_queue = queue.Queue()\n",
    "        self.call_queue.put((\"upload\", [], {\"file\": file_path}, result_queue))\n",
    "        result = result_queue.get()\n",
    "        \n",
    "        if \"error\" in result:\n",
    "            raise Exception(result[\"error\"])\n",
    "            \n",
    "        # Cache the uploaded file\n",
    "        self.file_cache[cache_key] = result[\"response\"]\n",
    "        return result[\"response\"]\n",
    "\n",
    "    def generate_content(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Make an API call to generate content, automatically handling key rotation.\n",
    "\n",
    "        Returns:\n",
    "            The response from the API call.\n",
    "        \"\"\"\n",
    "        result_queue = queue.Queue()\n",
    "        self.call_queue.put((\"generate\", args, kwargs, result_queue))\n",
    "        result = result_queue.get()\n",
    "        \n",
    "        if \"error\" in result:\n",
    "            raise Exception(result[\"error\"])\n",
    "        return result[\"response\"]\n",
    "\n",
    "    def reset_usage_counts(self):\n",
    "        \"\"\"Reset the usage counts for all keys (e.g., at the start of a new day).\"\"\"\n",
    "        self.usage_count = {key: 0 for key in self.api_keys}\n",
    "        self.file_cache.clear()  # Clear file cache when resetting\n",
    "        logging.info(\"Reset API key usage counts and file cache\")\n",
    "\n",
    "    def get_usage_stats(self):\n",
    "        \"\"\"Get usage statistics for all keys.\"\"\"\n",
    "        total_used = sum(self.usage_count.values())\n",
    "        total_available = len(self.api_keys) * self.calls_per_day\n",
    "        return {\n",
    "            \"per_key\": self.usage_count,\n",
    "            \"total_used\": total_used,\n",
    "            \"total_available\": total_available,\n",
    "            \"percent_used\": (total_used / total_available) * 100 if total_available > 0 else 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:33:22.365448Z",
     "iopub.status.busy": "2025-07-14T06:33:22.365214Z",
     "iopub.status.idle": "2025-07-14T06:33:22.388071Z",
     "shell.execute_reply": "2025-07-14T06:33:22.386867Z",
     "shell.execute_reply.started": "2025-07-14T06:33:22.365429Z"
    },
    "papermill": {
     "duration": 0.027572,
     "end_time": "2025-06-18T08:12:02.60087",
     "exception": false,
     "start_time": "2025-06-18T08:12:02.573298",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_predicates_with_reasoning(api_manager, image_path, question):\n",
    "    \"\"\"\n",
    "    Generate geometric predicates with step-by-step reasoning using Gemini Vision.\n",
    "\n",
    "    Args:\n",
    "        api_manager: GeminiVisionApiManager instance\n",
    "        image_path (str): Path to the geometry problem image\n",
    "        question (str): Question to analyze\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains 'reasoning', 'predicates', and 'raw_content'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Upload the image file\n",
    "        uploaded_file = api_manager.upload_file(image_path)\n",
    "        \n",
    "        # Enhanced prompt with reasoning requirements\n",
    "        prompt = f\"\"\"You are an expert AI mathematician specializing in geometry. Your task is to analyze the geometric figure in the provided image and generate accurate geometric predicates (literals) that represent ALL the relationships, measurements, and properties shown in the diagram.\n",
    "\n",
    "GEOMETRY PROBLEM IMAGE:\n",
    "The image shows a geometric figure with various shapes, lines, angles, and measurements. Analyze this image carefully to understand all geometric relationships and constraints.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "YOUR TASK:\n",
    "1. First, provide step-by-step reasoning showing your analysis process\n",
    "2. Then, generate geometric predicates based on your analysis using the Guidelines below\n",
    "\n",
    "STEP-BY-STEP ANALYSIS (Required):\n",
    "Please follow this format for your reasoning:\n",
    "\n",
    "STEP 1: QUESTION ANALYSIS AND REQUIREMENTS\n",
    "- Carefully read and understand what the question is asking\n",
    "- Identify the target variable(s) or property to be found\n",
    "- Determine what geometric relationships are needed to solve the problem\n",
    "- Note any specific theorems, formulas, or concepts the question hints at\n",
    "- Identify which elements in the diagram are most relevant to the question\n",
    "\n",
    "STEP 2: COMPREHENSIVE IMAGE ANALYSIS\n",
    "- Identify ALL geometric shapes (circles, triangles, quadrilaterals, etc.)\n",
    "- List ALL points, lines, and their labels/names\n",
    "- Note ALL visible measurements, angles, and numerical values\n",
    "- Identify ALL special markings (right angle symbols, parallel marks, congruent marks, equal marks, etc.)\n",
    "- Look for implied constructions (perpendiculars, bisectors, tangents, chords, radii, etc.)\n",
    "\n",
    "STEP 3: CIRCLE-SPECIFIC ANALYSIS (If circles are present)\n",
    "- Identify the center and all points on the circle\n",
    "- Determine which lines are radii, chords, diameters, or tangents\n",
    "- Look for inscribed angles, central angles, and arc relationships\n",
    "- Check for perpendicular relationships involving radii and chords\n",
    "- Identify any equal radius relationships\n",
    "\n",
    "STEP 4: ANGLE AND PERPENDICULARITY ANALYSIS\n",
    "- Examine ALL angles shown in the diagram, both marked and unmarked\n",
    "- Look for right angle indicators or perpendicular relationships\n",
    "- Check for angle bisectors or special angle relationships\n",
    "- Identify complementary, supplementary, or vertical angles\n",
    "- Look for inscribed angles and their corresponding arcs\n",
    "\n",
    "STEP 5: CONGRUENCE AND EQUALITY ANALYSIS\n",
    "- Identify ALL equal lengths, angles, or shapes (look for tick marks, identical measurements)\n",
    "- Check for congruent triangles or similar figures\n",
    "- Look for equal radii in circles\n",
    "- Identify parallel lines or equal distances\n",
    "\n",
    "STEP 6: INTERSECTION AND POSITIONING ANALYSIS\n",
    "- Determine where lines intersect and at what points\n",
    "- Check if points lie on specific lines or circles\n",
    "- Identify midpoints, centroids, or other special points\n",
    "- Look for points that divide segments in specific ratios\n",
    "\n",
    "STEP 7: CONSTRAINT AND RELATIONSHIP SYNTHESIS\n",
    "- Combine observations to identify implicit relationships\n",
    "- Look for theorem applications (Pythagorean, inscribed angle, etc.)\n",
    "- Identify geometric constructions that create specific relationships\n",
    "- Check for properties that follow from the given constraints\n",
    "\n",
    "STEP 8: QUESTION-DRIVEN COMPLETENESS CHECK\n",
    "- Ensure all information needed to solve the problem is captured\n",
    "- Verify that key relationships for the solution are represented\n",
    "- Double-check that no critical geometric properties are missed\n",
    "- Confirm that the predicates will provide sufficient information for problem-solving\n",
    "- **CROSS-REFERENCE WITH QUESTION**: Make sure all geometric elements mentioned in or required by the question are fully represented in your predicates\n",
    "\n",
    "STEP 9: SOLUTION PATH VALIDATION\n",
    "- Mentally trace through how the question could be solved using your identified relationships\n",
    "- Ensure no missing links in the logical chain from given information to solution\n",
    "- Add any implicit relationships that are necessary for the solution process\n",
    "- Verify that common geometric theorems and principles are adequately represented\n",
    "\n",
    "CRITICAL ANALYSIS GUIDELINES:\n",
    "⚠️ **QUESTION-FIRST APPROACH**: Let the question guide your analysis - if the question asks about area, ensure all length relationships are captured; if about angles, ensure all angle relationships are identified.\n",
    "\n",
    "⚠️ **LOOK FOR HIDDEN RELATIONSHIPS**: Many geometric problems have implicit perpendicular relationships, equal lengths, or special angle properties that aren't explicitly marked but are crucial for solving.\n",
    "\n",
    "⚠️ **CIRCLE GEOMETRY FOCUS**: If the diagram contains circles, pay special attention to:\n",
    "- Which points lie on the circle vs. inside/outside\n",
    "- Perpendicular relationships between radii and chords\n",
    "- Equal radius lengths\n",
    "- Inscribed vs. central angles\n",
    "- Tangent-radius perpendicularity\n",
    "\n",
    "⚠️ **CONSTRUCTION INDICATORS**: Look for:\n",
    "- Lines that appear to be perpendicular even without explicit markings\n",
    "- Points that appear to be midpoints or special positions\n",
    "- Equal lengths suggested by visual symmetry\n",
    "- Angle relationships implied by the construction\n",
    "\n",
    "⚠️ **SOLUTION-CRITICAL RELATIONSHIPS**: Based on the question, prioritize identifying:\n",
    "- Relationships that directly connect to what's being asked\n",
    "- Intermediate relationships needed for multi-step solutions\n",
    "- Theorem prerequisites (e.g., if Pythagorean theorem is needed, ensure right angles are identified)\n",
    "\n",
    "GUIDELINES:\n",
    "***Follow these predicates to represent diagram literals.\n",
    "\n",
    "**GEOMETRIC SHAPES:**\n",
    "- Point: Point(A), Point($)\n",
    "- Line: Line(A,B), Line(m), Line($)\n",
    "- Angle: Angle(A,B,C), Angle(A), Angle(1), Angle($)\n",
    "- Triangle: Triangle(A,B,C), Triangle($), Triangle($1,$2,$3)\n",
    "- Quadrilateral: Quadrilateral(A,B,C,D), Quadrilateral($)\n",
    "- Parallelogram: Parallelogram(A,B,C,D), Parallelogram(1), Parallelogram($)\n",
    "- Square: Square(A,B,C,D), Square(1), Square($)\n",
    "- Rectangle: Rectangle(A,B,C,D), Rectangle(1), Rectangle($)\n",
    "- Rhombus: Rhombus(A,B,C,D), Rhombus(1), Rhombus($)\n",
    "- Trapezoid: Trapezoid(A,B,C,D), Trapezoid(1), Trapezoid($)\n",
    "- Kite: Kite(A,B,C,D), Kite(1), Kite($)\n",
    "- Polygon: Polygon($)\n",
    "- Pentagon: Pentagon(A,B,C,D,E), Pentagon($)\n",
    "- Hexagon: Hexagon(A,B,C,D,E,F), Hexagon($)\n",
    "- Heptagon: Heptagon(A,B,C,D,E,F,G), Heptagon($)\n",
    "- Octagon: Octagon(A,B,C,D,E,F,G,H), Octagon($)\n",
    "- Circle: Circle(A), Circle(1), Circle($)\n",
    "- Arc: Arc(A,B), Arc(A,B,C), Arc($)\n",
    "- Sector: Sector(O,A,B), Sector($)\n",
    "- Shape: Shape($) // For unknown shapes or regions\n",
    "\n",
    "**UNARY GEOMETRIC ATTRIBUTES:**\n",
    "- RightAngle: RightAngle(Angle($))\n",
    "- Right: Right(Triangle($)) // Right triangle\n",
    "- Isosceles: Isosceles(Polygon($)) // Isosceles polygon\n",
    "- Equilateral: Equilateral(Polygon($)) // Equilateral polygon\n",
    "- Regular: Regular(Polygon($))\n",
    "- Red: Red(Shape($))\n",
    "- Blue: Blue(Shape($))\n",
    "- Green: Green(Shape($))\n",
    "- Shaded: Shaded(Shape($))\n",
    "\n",
    "**GEOMETRIC ATTRIBUTES:**\n",
    "- AreaOf: AreaOf(A)\n",
    "- PerimeterOf: PerimeterOf(A) // Perimeter of polygon A\n",
    "- RadiusOf: RadiusOf(A)\n",
    "- DiameterOf: DiameterOf(A)\n",
    "- CircumferenceOf: CircumferenceOf(A) // Perimeter of circle A\n",
    "- AltitudeOf: AltitudeOf(A) // Altitude of polygon A\n",
    "- HypotenuseOf: HypotenuseOf(A) // Hypotenuse of triangle A\n",
    "- SideOf: SideOf(A) // Side of square A\n",
    "- WidthOf: WidthOf(A) // Width of quadrilateral A\n",
    "- HeightOf: HeightOf(A) // Height of quadrilateral A\n",
    "- LegOf: LegOf(A) // Leg of trapezoid A\n",
    "- BaseOf: BaseOf(A) // Base of polygon A\n",
    "- MedianOf: MedianOf(A) // Median of polygon A\n",
    "- IntersectionOf: IntersectionOf(A,B) // Intersection of shapes A and B\n",
    "- MeasureOf: MeasureOf(A) // Measure of angle A\n",
    "- LengthOf: LengthOf(A) // Length of line A\n",
    "- ScaleFactorOf: ScaleFactorOf(A,B) // Scale factor of shape A to shape B\n",
    "\n",
    "**BINARY GEOMETRIC RELATIONS:**\n",
    "- PointLiesOnLine: PointLiesOnLine(Point($),Line($1,$2))\n",
    "- PointLiesOnCircle: PointLiesOnCircle(Point($),Circle($))\n",
    "- Parallel: Parallel(Line($),Line($))\n",
    "- Perpendicular: Perpendicular(Line($),Line($))\n",
    "- IntersectAt: IntersectAt(Line($),Line($),Line($),Point($))\n",
    "- BisectsAngle: BisectsAngle(Line($),Angle($))\n",
    "- Congruent: Congruent(Polygon($),Polygon($))\n",
    "- Similar: Similar(Polygon($),Polygon($))\n",
    "- Tangent: Tangent(Line($),Circle($))\n",
    "- Secant: Secant(Line($),Circle($))\n",
    "- CircumscribedTo: CircumscribedTo(Shape($),Shape($))\n",
    "- InscribedIn: InscribedIn(Shape($),Shape($))\n",
    "\n",
    "**A-IsXOf-B GEOMETRIC RELATIONS:**\n",
    "- IsMidpointOf: IsMidpointOf(Point($),Line($)) // Point A is midpoint of line B\n",
    "- IsCentroidOf: IsCentroidOf(Point($),Shape($)) // Point A is centroid of shape B\n",
    "- IsIncenterOf: IsIncenterOf(Point($),Shape($)) // Point A is incenter of shape B\n",
    "- IsRadiusOf: IsRadiusOf(Line($),Circle($)) // Line A is radius of circle B\n",
    "- IsDiameterOf: IsDiameterOf(Line($),Circle($)) // Line A is diameter of circle B\n",
    "- IsMidsegmentOf: IsMidsegmentOf(Line($),Triangle($)) // Line A is midsegment of triangle B\n",
    "- IsChordOf: IsChordOf(Line($),Circle($)) // Line A is chord of circle B\n",
    "- IsSideOf: IsSideOf(Line($),Polygon($)) // Line A is side of polygon B\n",
    "- IsHypotenuseOf: IsHypotenuseOf(Line($),Triangle($)) // Line A is hypotenuse of triangle B\n",
    "- IsPerpendicularBisectorOf: IsPerpendicularBisectorOf(Line($),Triangle($)) // Line A is perpendicular bisector of triangle B\n",
    "- IsAltitudeOf: IsAltitudeOf(Line($),Triangle($)) // Line A is altitude of triangle B\n",
    "- IsMedianOf: IsMedianOf(Line($),Quadrilateral($)) // Line A is median of quadrilateral B\n",
    "- IsBaseOf: IsBaseOf(Line($),Quadrilateral($)) // Line A is base of quadrilateral B\n",
    "- IsDiagonalOf: IsDiagonalOf(Line($),Quadrilateral($)) // Line A is diagonal of quadrilateral B\n",
    "- IsLegOf: IsLegOf(Line($),Trapezoid($)) // Line A is leg of trapezoid B\n",
    "\n",
    "**NUMERICAL ATTRIBUTES AND RELATIONS:**\n",
    "- SinOf: SinOf(Var)\n",
    "- CosOf: CosOf(Var)\n",
    "- TanOf: TanOf(Var)\n",
    "- CotOf: CotOf(Var)\n",
    "- HalfOf: HalfOf(Var)\n",
    "- SquareOf: SquareOf(Var)\n",
    "- SqrtOf: SqrtOf(Var)\n",
    "- RatioOf: RatioOf(Var), RatioOf(Var1,Var2)\n",
    "- SumOf: SumOf(Var1,Var2,...)\n",
    "- AverageOf: AverageOf(Var1,Var2,...)\n",
    "- Add: Add(Var1,Var2,...)\n",
    "- Mul: Mul(Var1,Var2,...)\n",
    "- Sub: Sub(Var1,Var2,...)\n",
    "- Div: Div(Var1,Var2,...)\n",
    "- Pow: Pow(Var1,Var2)\n",
    "- Equals: Equals(Var1,Var2)\n",
    "- Find: Find(Var) // Find the value of the variable\n",
    "- UseTheorem: UseTheorem(A_B_C)\n",
    "\n",
    "VARIABLE NAMING CONVENTIONS:\n",
    "- Use capital letters for points: A, B, C, D, etc.\n",
    "- Use lowercase letters for lines when not defined by points: m, n, l, etc.\n",
    "- Use numbers for unnamed shapes: 1, 2, 3, etc.\n",
    "- Use $ for generic variables: $, $1, $2, etc.\n",
    "- Use descriptive names when appropriate: base, height, radius, etc.\n",
    "\n",
    "CRITICAL INSTRUCTIONS:\n",
    "1. **BE EXTREMELY THOROUGH** - Missing relationships are the main cause of poor problem-solving performance\n",
    "2. **QUESTION-DRIVEN ANALYSIS** - Use the question to guide which relationships are most critical to identify\n",
    "3. **LOOK BEYOND THE OBVIOUS** - Many critical relationships are implied, not explicitly marked\n",
    "4. Carefully examine the geometric figure in the image\n",
    "5. Identify all points, lines, angles, shapes, and measurements shown\n",
    "6. **MAKE EACH PREDICATE AS ATOMIC AS POSSIBLE** \n",
    "   – Decompose any complex or compound relationship into the simplest, individual geometric \n",
    "     statements (e.g., replace \"Perpendicular(Line(A,B),Line(C,D))\" with separate vector and dot-product or angle-equals-90° predicates)\n",
    "7. Generate predicates that represent:\n",
    "   - All geometric shapes present\n",
    "   - All given measurements and their relationships\n",
    "   - All geometric properties and constraints (including implied ones)\n",
    "   - ALL relationships between different elements\n",
    "   - All perpendicular relationships (marked and implied)\n",
    "   - All equal lengths and angles (marked and implied)\n",
    "   - **All relationships specifically needed to answer the question**\n",
    "8. Always provide the step-by-step reasoning first\n",
    "9. Then provide the predicates section with a clear section header\n",
    "10. Follow the Guidelines above - these predicates are crucial for representing diagram literals\n",
    "11. Each predicate must be on a separate line\n",
    "12. Do not include quotation marks, extra symbols, or explanatory text in predicates\n",
    "13. Only output predicates in the exact format: PredicateName(arguments)\n",
    "14. **IMPORTANT: Do NOT include any question-related predicates**\n",
    "15. Include only the given information, constraints, and geometric relationships visible in the diagram\n",
    "16. Represent all visible geometric relationships, not derived solutions\n",
    "17. The predicates should provide sufficient information for another system to solve the problem, but not the solution itself\n",
    "18. **COMPLETENESS IS KEY** - Better to include extra relationships than miss critical ones\n",
    "19. **QUESTION COMPLETENESS** - Ensure your predicates capture all relationships necessary for solving the specific question asked\n",
    "\n",
    "Generate your complete analysis and predicates now:\n",
    "\"\"\"\n",
    "\n",
    "        # Generate content with the uploaded image and prompt\n",
    "        response = api_manager.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            contents=[uploaded_file, prompt]\n",
    "        )\n",
    "\n",
    "        raw_content = response.text.strip()\n",
    "        \n",
    "        # Parse the response to separate reasoning and predicates\n",
    "        reasoning_section = \"\"\n",
    "        predicates_section = \"\"\n",
    "        \n",
    "        if \"STEP-BY-STEP REASONING:\" in raw_content and \"GENERATED PREDICATES:\" in raw_content:\n",
    "            parts = raw_content.split(\"GENERATED PREDICATES:\")\n",
    "            reasoning_section = parts[0].replace(\"STEP-BY-STEP REASONING:\", \"\").strip()\n",
    "            predicates_section = parts[1].strip()\n",
    "        elif \"GENERATED PREDICATES:\" in raw_content:\n",
    "            parts = raw_content.split(\"GENERATED PREDICATES:\")\n",
    "            reasoning_section = \"No explicit reasoning provided\"\n",
    "            predicates_section = parts[1].strip()\n",
    "        else:\n",
    "            # Try to extract predicates from the entire content\n",
    "            reasoning_section = raw_content\n",
    "            predicates_section = raw_content\n",
    "\n",
    "        return {\n",
    "            'reasoning': reasoning_section,\n",
    "            'predicates': predicates_section,\n",
    "            'raw_content': raw_content\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing image {image_path}: {e}\")\n",
    "        return {\n",
    "            'reasoning': f'Error during reasoning: {str(e)}',\n",
    "            'predicates': f'Error processing image: {str(e)}',\n",
    "            'raw_content': f'Error: {str(e)}'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:33:22.389188Z",
     "iopub.status.busy": "2025-07-14T06:33:22.388948Z",
     "iopub.status.idle": "2025-07-14T06:33:22.414518Z",
     "shell.execute_reply": "2025-07-14T06:33:22.413535Z",
     "shell.execute_reply.started": "2025-07-14T06:33:22.389168Z"
    },
    "papermill": {
     "duration": 0.025927,
     "end_time": "2025-06-18T08:12:02.638424",
     "exception": false,
     "start_time": "2025-06-18T08:12:02.612497",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def self_validate_predicates(api_manager, image_path, question, generated_predicates, reasoning):\n",
    "    \"\"\"\n",
    "    Have the LLM validate its own generated predicates.\n",
    "    \n",
    "    Args:\n",
    "        api_manager: GeminiVisionApiManager instance\n",
    "        image_path (str): Path to the geometry problem image\n",
    "        question (str): Original question\n",
    "        generated_predicates (str): The predicates generated by the model\n",
    "        reasoning (str): The reasoning process used\n",
    "        \n",
    "    Returns:\n",
    "        dict: Contains validation judgment and scores\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Upload the image file (reuse cache if available)\n",
    "        uploaded_file = api_manager.upload_file(image_path)\n",
    "        \n",
    "        validation_prompt = f\"\"\"You are now acting as a critical reviewer of your own work. You previously analyzed a geometry problem and generated predicates. Now you must validate your own output.\n",
    "\n",
    "ORIGINAL PROBLEM:\n",
    "Question: {question}\n",
    "\n",
    "YOUR PREVIOUS REASONING:\n",
    "{reasoning}\n",
    "\n",
    "YOUR GENERATED PREDICATES:\n",
    "{generated_predicates}\n",
    "\n",
    "SELF-VALIDATION TASK:\n",
    "Critically evaluate your own work by analyzing the following aspects:\n",
    "\n",
    "1. COMPLETENESS ANALYSIS:\n",
    "   - Does the image contain geometric elements that you missed?\n",
    "   - Are all visible measurements and relationships captured?\n",
    "   - Are there implicit relationships you should have included?\n",
    "\n",
    "2. ACCURACY ANALYSIS:\n",
    "   - Are all predicates mathematically correct?\n",
    "   - Do the predicates accurately represent what's shown in the image?\n",
    "   - Are there any contradictory or inconsistent predicates?\n",
    "\n",
    "3. FORMAT ANALYSIS:\n",
    "   - Are all predicates in the correct format: PredicateName(arguments)?\n",
    "   - Are predicate names from the valid set of allowed predicates?\n",
    "   - Are there any syntax errors or typos?\n",
    "\n",
    "4. CONSISTENCY ANALYSIS:\n",
    "   - Do the predicates logically support solving the problem?\n",
    "   - Are there mathematical relationships that contradict each other?\n",
    "   - Do numerical values make sense in context?\n",
    "\n",
    "5. RELEVANCE ANALYSIS:\n",
    "   - Are all predicates relevant to solving the problem?\n",
    "   - Are there unnecessary or redundant predicates?\n",
    "   - Do the predicates focus on what the question is asking?\n",
    "\n",
    "PROVIDE YOUR VALIDATION JUDGMENT:\n",
    "\n",
    "OVERALL ASSESSMENT: [EXCELLENT/GOOD/FAIR/POOR]\n",
    "\n",
    "DETAILED ANALYSIS:\n",
    "\n",
    "COMPLETENESS SCORE: [1-10] /10\n",
    "Explanation: [Your assessment of completeness]\n",
    "\n",
    "ACCURACY SCORE: [1-10] /10\n",
    "Explanation: [Your assessment of accuracy]\n",
    "\n",
    "FORMAT SCORE: [1-10] /10\n",
    "Explanation: [Your assessment of format correctness]\n",
    "\n",
    "CONSISTENCY SCORE: [1-10] /10\n",
    "Explanation: [Your assessment of logical consistency]\n",
    "\n",
    "RELEVANCE SCORE: [1-10] /10\n",
    "Explanation: [Your assessment of relevance]\n",
    "\n",
    "SPECIFIC ISSUES IDENTIFIED:\n",
    "[List any specific problems you found]\n",
    "\n",
    "MISSING ELEMENTS:\n",
    "[List anything important that was missed]\n",
    "\n",
    "INCORRECT ELEMENTS:\n",
    "[List anything that appears to be wrong]\n",
    "\n",
    "SUGGESTED IMPROVEMENTS:\n",
    "[Provide specific suggestions for improvement]\n",
    "\n",
    "CONFIDENCE IN PROBLEM SOLVING: [1-10] /10\n",
    "Explanation: [How well do your predicates support solving the problem]\n",
    "\n",
    "FINAL RECOMMENDATION: [ACCEPT/REVISE/REJECT]\n",
    "Reasoning: [Brief explanation of your recommendation]\n",
    "\"\"\"\n",
    "\n",
    "        # Generate validation content\n",
    "        response = api_manager.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            contents=[uploaded_file, validation_prompt]\n",
    "        )\n",
    "\n",
    "        validation_content = response.text.strip()\n",
    "        \n",
    "        # Parse scores from the validation content\n",
    "        scores = {}\n",
    "        try:\n",
    "            # Extract scores using regex\n",
    "            score_patterns = {\n",
    "                'completeness': r'COMPLETENESS SCORE:\\s*(\\d+)',\n",
    "                'accuracy': r'ACCURACY SCORE:\\s*(\\d+)',\n",
    "                'format': r'FORMAT SCORE:\\s*(\\d+)',\n",
    "                'consistency': r'CONSISTENCY SCORE:\\s*(\\d+)',\n",
    "                'relevance': r'RELEVANCE SCORE:\\s*(\\d+)',\n",
    "                'confidence': r'CONFIDENCE IN PROBLEM SOLVING:\\s*(\\d+)'\n",
    "            }\n",
    "            \n",
    "            for score_name, pattern in score_patterns.items():\n",
    "                match = re.search(pattern, validation_content, re.IGNORECASE)\n",
    "                if match:\n",
    "                    scores[score_name] = int(match.group(1))\n",
    "                else:\n",
    "                    scores[score_name] = 0\n",
    "            \n",
    "            # Extract overall assessment\n",
    "            overall_match = re.search(r'OVERALL ASSESSMENT:\\s*\\[?([A-Z]+)\\]?', validation_content, re.IGNORECASE)\n",
    "            overall_assessment = overall_match.group(1) if overall_match else \"UNKNOWN\"\n",
    "            \n",
    "            # Extract final recommendation\n",
    "            recommendation_match = re.search(r'FINAL RECOMMENDATION:\\s*\\[?([A-Z]+)\\]?', validation_content, re.IGNORECASE)\n",
    "            final_recommendation = recommendation_match.group(1) if recommendation_match else \"UNKNOWN\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error parsing validation scores: {e}\")\n",
    "            scores = {\n",
    "                'completeness': 0, 'accuracy': 0, 'format': 0, \n",
    "                'consistency': 0, 'relevance': 0, 'confidence': 0\n",
    "            }\n",
    "            overall_assessment = \"ERROR\"\n",
    "            final_recommendation = \"ERROR\"\n",
    "\n",
    "        return {\n",
    "            'validation_content': validation_content,\n",
    "            'scores': scores,\n",
    "            'overall_assessment': overall_assessment,\n",
    "            'final_recommendation': final_recommendation,\n",
    "            'average_score': sum(scores.values()) / len(scores) if scores else 0\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in self-validation: {e}\")\n",
    "        return {\n",
    "            'validation_content': f'Error during self-validation: {str(e)}',\n",
    "            'scores': {'completeness': 0, 'accuracy': 0, 'format': 0, 'consistency': 0, 'relevance': 0, 'confidence': 0},\n",
    "            'overall_assessment': 'ERROR',\n",
    "            'final_recommendation': 'ERROR',\n",
    "            'average_score': 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:33:22.416005Z",
     "iopub.status.busy": "2025-07-14T06:33:22.415657Z",
     "iopub.status.idle": "2025-07-14T06:33:22.441692Z",
     "shell.execute_reply": "2025-07-14T06:33:22.440812Z",
     "shell.execute_reply.started": "2025-07-14T06:33:22.415940Z"
    },
    "papermill": {
     "duration": 0.019792,
     "end_time": "2025-06-18T08:12:02.670256",
     "exception": false,
     "start_time": "2025-06-18T08:12:02.650464",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_predicates(predicates_content):\n",
    "    \"\"\"\n",
    "    Extract clean predicates from the model output.\n",
    "    \n",
    "    Args:\n",
    "        predicates_content (str): The predicates section content\n",
    "        \n",
    "    Returns:\n",
    "        list: List of clean predicates\n",
    "    \"\"\"\n",
    "    if not predicates_content or not predicates_content.strip():\n",
    "        return []\n",
    "    \n",
    "    # Clean the input: remove excessive whitespace but preserve structure\n",
    "    content = re.sub(r'\\s+', ' ', predicates_content.strip())\n",
    "    \n",
    "    predicates = []\n",
    "    i = 0\n",
    "    n = len(content)\n",
    "    \n",
    "    while i < n:\n",
    "        # Skip whitespace and common separators\n",
    "        while i < n and content[i] in ' \\t\\n\\r,;.':\n",
    "            i += 1\n",
    "        \n",
    "        if i >= n:\n",
    "            break\n",
    "            \n",
    "        # Skip comments\n",
    "        if i < n - 1 and content[i:i+2] == '//':\n",
    "            # Skip C-style comments\n",
    "            while i < n and content[i] != '\\n':\n",
    "                i += 1\n",
    "            continue\n",
    "        elif content[i] == '#':\n",
    "            # Skip Python-style comments\n",
    "            while i < n and content[i] != '\\n':\n",
    "                i += 1\n",
    "            continue\n",
    "        \n",
    "        # Look for a potential predicate start\n",
    "        start_pos = i\n",
    "        predicate_buffer = \"\"\n",
    "        \n",
    "        # Collect characters until we find a complete predicate or reach end\n",
    "        paren_count = 0\n",
    "        in_string = False\n",
    "        string_char = None\n",
    "        escape_next = False\n",
    "        found_opening_paren = False\n",
    "        \n",
    "        while i < n:\n",
    "            char = content[i]\n",
    "            predicate_buffer += char\n",
    "            \n",
    "            if escape_next:\n",
    "                escape_next = False\n",
    "            elif char == '\\\\':\n",
    "                escape_next = True\n",
    "            elif in_string:\n",
    "                if char == string_char:\n",
    "                    in_string = False\n",
    "                    string_char = None\n",
    "            elif char in '\"\\'':\n",
    "                in_string = True\n",
    "                string_char = char\n",
    "            elif char == '(':\n",
    "                paren_count += 1\n",
    "                found_opening_paren = True\n",
    "            elif char == ')':\n",
    "                paren_count -= 1\n",
    "                \n",
    "                # Check if we have a complete predicate\n",
    "                if paren_count == 0 and found_opening_paren:\n",
    "                    candidate = predicate_buffer.strip()\n",
    "                    if _is_valid_predicate(candidate):\n",
    "                        predicates.append(candidate)\n",
    "                    break\n",
    "            elif not found_opening_paren and char in ',;\\n' and paren_count == 0:\n",
    "                # We hit a separator before finding a predicate, abandon this candidate\n",
    "                break\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        # If we didn't find a complete predicate, move to next character\n",
    "        if paren_count != 0 or not found_opening_paren:\n",
    "            i = start_pos + 1\n",
    "        else:\n",
    "            i += 1\n",
    "    \n",
    "    return _deduplicate_predicates(predicates)\n",
    "\n",
    "def _is_valid_predicate(candidate):\n",
    "    \"\"\"\n",
    "    Validates if a candidate string is a valid predicate.\n",
    "    Optimized for geometric predicates like Point(A), Triangle(A,B,C), etc.\n",
    "    \n",
    "    Args:\n",
    "        candidate (str): The candidate predicate string\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if valid predicate, False otherwise\n",
    "    \"\"\"\n",
    "    if not candidate or not candidate.strip():\n",
    "        return False\n",
    "    \n",
    "    candidate = candidate.strip()\n",
    "    \n",
    "    # Must start and end with proper characters\n",
    "    if not candidate.endswith(')'):\n",
    "        return False\n",
    "    \n",
    "    # Find the opening parenthesis\n",
    "    paren_pos = candidate.find('(')\n",
    "    if paren_pos == -1:\n",
    "        return False\n",
    "    \n",
    "    # Extract predicate name\n",
    "    predicate_name = candidate[:paren_pos].strip()\n",
    "    \n",
    "    # Validate predicate name: must start with letter, can contain letters, numbers, underscores\n",
    "    if not re.match(r'^[A-Za-z][A-Za-z0-9_]*$', predicate_name):\n",
    "        return False\n",
    "    \n",
    "    # Check for minimum reasonable length (avoid single char false positives)\n",
    "    if len(predicate_name) < 2 and predicate_name.lower() not in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']:\n",
    "        return False\n",
    "    \n",
    "    # Extract arguments to ensure they're not empty\n",
    "    args_part = candidate[paren_pos+1:-1].strip()\n",
    "    if not args_part:  # Empty parentheses are invalid for geometric predicates\n",
    "        return False\n",
    "    \n",
    "    # Check that parentheses are balanced\n",
    "    return _check_balanced_parentheses(candidate)\n",
    "\n",
    "def _check_balanced_parentheses(text):\n",
    "    \"\"\"\n",
    "    Check if parentheses are properly balanced, considering string literals.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to check\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if balanced, False otherwise\n",
    "    \"\"\"\n",
    "    paren_count = 0\n",
    "    in_string = False\n",
    "    string_char = None\n",
    "    escape_next = False\n",
    "    \n",
    "    for char in text:\n",
    "        if escape_next:\n",
    "            escape_next = False\n",
    "        elif char == '\\\\':\n",
    "            escape_next = True\n",
    "        elif in_string:\n",
    "            if char == string_char:\n",
    "                in_string = False\n",
    "                string_char = None\n",
    "        elif char in '\"\\'':\n",
    "            in_string = True\n",
    "            string_char = char\n",
    "        elif char == '(':\n",
    "            paren_count += 1\n",
    "        elif char == ')':\n",
    "            paren_count -= 1\n",
    "            if paren_count < 0:\n",
    "                return False\n",
    "    \n",
    "    return paren_count == 0 and not in_string\n",
    "\n",
    "def _deduplicate_predicates(predicates):\n",
    "    \"\"\"\n",
    "    Remove duplicate predicates while preserving order.\n",
    "    \n",
    "    Args:\n",
    "        predicates (list): List of predicates that may contain duplicates\n",
    "        \n",
    "    Returns:\n",
    "        list: List with duplicates removed\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    result = []\n",
    "    \n",
    "    for predicate in predicates:\n",
    "        # Normalize for comparison (remove extra spaces)\n",
    "        normalized = re.sub(r'\\s+', ' ', predicate.strip())\n",
    "        if normalized not in seen:\n",
    "            seen.add(normalized)\n",
    "            result.append(predicate.strip())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:33:22.442829Z",
     "iopub.status.busy": "2025-07-14T06:33:22.442570Z",
     "iopub.status.idle": "2025-07-14T06:33:22.458402Z",
     "shell.execute_reply": "2025-07-14T06:33:22.457473Z",
     "shell.execute_reply.started": "2025-07-14T06:33:22.442802Z"
    },
    "papermill": {
     "duration": 0.02443,
     "end_time": "2025-06-18T08:12:02.706314",
     "exception": false,
     "start_time": "2025-06-18T08:12:02.681884",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_predicates_with_retry(api_manager, image_path, question, max_retries=3):\n",
    "    \"\"\"\n",
    "    Generate predicates with retry mechanism, reasoning, and self-validation.\n",
    "    \n",
    "    Args:\n",
    "        api_manager: GeminiVisionApiManager instance\n",
    "        image_path (str): Path to the geometry problem image\n",
    "        question (str): Question to analyze\n",
    "        max_retries (int): Maximum number of retry attempts\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (predicates_list, reasoning, validation_result, full_content)\n",
    "    \"\"\"\n",
    "    problem_num = os.path.basename(image_path).split('.')[0]\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Generate predicates with reasoning\n",
    "            result = generate_predicates_with_reasoning(api_manager, image_path, question)\n",
    "            reasoning = result['reasoning']\n",
    "            predicates_content = result['predicates']\n",
    "            raw_content = result['raw_content']\n",
    "            \n",
    "            # Extract clean predicates\n",
    "            predicates = extract_predicates(predicates_content)\n",
    "            \n",
    "            if len(predicates) > 0:\n",
    "                # Self-validate the generated predicates\n",
    "                validation_result = self_validate_predicates(\n",
    "                    api_manager, image_path, question, \n",
    "                    predicates_content, reasoning\n",
    "                )\n",
    "                \n",
    "                logging.info(f\"Attempt {attempt + 1} for problem {problem_num}: Generated {len(predicates)} predicates, Average score: {validation_result['average_score']:.1f}\")\n",
    "                \n",
    "                # Accept if average score is reasonable or if we're on the last attempt\n",
    "                if validation_result['average_score'] >= 6.0 or attempt == max_retries - 1:\n",
    "                    return predicates, reasoning, validation_result, raw_content\n",
    "                else:\n",
    "                    logging.warning(f\"Attempt {attempt + 1} for problem {problem_num}: Low validation score ({validation_result['average_score']:.1f}), retrying...\")\n",
    "                    \n",
    "            else:\n",
    "                logging.warning(f\"Attempt {attempt + 1} for problem {problem_num}: No valid predicates extracted\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Attempt {attempt + 1} failed for problem {problem_num}: {str(e)}\")\n",
    "    \n",
    "    # If all attempts failed, return empty results\n",
    "    return [], \"All attempts failed\", {\n",
    "        'validation_content': 'All generation attempts failed',\n",
    "        'scores': {'completeness': 0, 'accuracy': 0, 'format': 0, 'consistency': 0, 'relevance': 0, 'confidence': 0},\n",
    "        'overall_assessment': 'FAILED',\n",
    "        'final_recommendation': 'FAILED',\n",
    "        'average_score': 0\n",
    "    }, \"Generation failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:33:22.460135Z",
     "iopub.status.busy": "2025-07-14T06:33:22.459481Z",
     "iopub.status.idle": "2025-07-14T06:33:22.487712Z",
     "shell.execute_reply": "2025-07-14T06:33:22.486934Z",
     "shell.execute_reply.started": "2025-07-14T06:33:22.460105Z"
    },
    "papermill": {
     "duration": 0.037904,
     "end_time": "2025-06-18T08:12:02.756104",
     "exception": false,
     "start_time": "2025-06-18T08:12:02.7182",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to process geometry problems and generate predicates using Gemini Vision API.\"\"\"\n",
    "    \n",
    "    # Initialize API keys\n",
    "    api_keys = [\n",
    "        \"your api keys\"\n",
    "    ]\n",
    "\n",
    "    # Initialize API manager\n",
    "    api_manager = GeminiVisionApiManager(\n",
    "        api_keys=api_keys,\n",
    "        calls_per_day=200,\n",
    "        rate_limit_delay=4  # 4 seconds to stay under 15 RPM\n",
    "    )\n",
    "\n",
    "    # Input directories\n",
    "    image_dir = \"image directory\"\n",
    "    questions_dir = \"question directory\"\n",
    "    \n",
    "    # Output directories\n",
    "    predicates_output_dir = \"/kaggle/working/predicates_output\"\n",
    "    reasoning_output_dir = \"/kaggle/working/reasoning_output\"\n",
    "    validation_output_dir = \"/kaggle/working/validation_output\"\n",
    "    combined_analysis_dir = \"/kaggle/working/combined_analysis\"\n",
    "    \n",
    "    for dir_path in [predicates_output_dir, reasoning_output_dir, validation_output_dir, combined_analysis_dir]:\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    logging.info(\"Starting Gemini Vision geometry predicate generation with reasoning and self-validation...\")\n",
    "    \n",
    "    # Process problems from 2401 to 3001 (change range as needed)\n",
    "    for num in tqdm(range(2401, 3002), desc=\"Processing problems\"):\n",
    "        num_str = str(num)\n",
    "        \n",
    "        # Paths to input files\n",
    "        image_path = os.path.join(image_dir, f\"{num_str}.png\")\n",
    "        ques_path = os.path.join(questions_dir, f\"{num_str}.txt\")\n",
    "        \n",
    "        # Check if all required files exist\n",
    "        if not all(os.path.exists(path) for path in [image_path, ques_path]):\n",
    "            print(f\"Skipping problem {num_str}: Missing input files\")\n",
    "            logging.warning(f\"Skipping problem {num_str}: Missing input files\")\n",
    "            continue\n",
    "        \n",
    "        # Read inputs\n",
    "        try:\n",
    "            with open(ques_path, \"r\", encoding='utf-8') as f:\n",
    "                question = f.read().strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading files for problem {num_str}: {e}\")\n",
    "            logging.error(f\"Error reading files for problem {num_str}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Generate predicates with reasoning and validation\n",
    "        try:\n",
    "            predicates, reasoning, validation_result, raw_content = generate_predicates_with_retry(\n",
    "                api_manager, image_path, question\n",
    "            )\n",
    "            \n",
    "            # Write predicates to output file (clean format)\n",
    "            predicates_out_path = os.path.join(predicates_output_dir, f\"{num_str}.txt\")\n",
    "            with open(predicates_out_path, \"w\", encoding='utf-8') as f:\n",
    "                for predicate in predicates:\n",
    "                    f.write(predicate + \"\\n\")\n",
    "            \n",
    "            # Write reasoning to separate file\n",
    "            reasoning_out_path = os.path.join(reasoning_output_dir, f\"{num_str}.txt\")\n",
    "            with open(reasoning_out_path, \"w\", encoding='utf-8') as f:\n",
    "                f.write(\"=\" * 80 + \"\\n\")\n",
    "                f.write(f\"PROBLEM {num_str} - STEP-BY-STEP REASONING\\n\")\n",
    "                f.write(\"=\" * 80 + \"\\n\")\n",
    "                f.write(f\"Question: {question}\\n\")\n",
    "                f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "                f.write(reasoning)\n",
    "            \n",
    "            # Write validation results to separate file\n",
    "            validation_out_path = os.path.join(validation_output_dir, f\"{num_str}.txt\")\n",
    "            with open(validation_out_path, \"w\", encoding='utf-8') as f:\n",
    "                f.write(\"=\" * 80 + \"\\n\")\n",
    "                f.write(f\"PROBLEM {num_str} - SELF-VALIDATION RESULTS\\n\")\n",
    "                f.write(\"=\" * 80 + \"\\n\")\n",
    "                f.write(f\"Overall Assessment: {validation_result['overall_assessment']}\\n\")\n",
    "                f.write(f\"Final Recommendation: {validation_result['final_recommendation']}\\n\")\n",
    "                f.write(f\"Average Score: {validation_result['average_score']:.2f}/10\\n\\n\")\n",
    "                \n",
    "                f.write(\"DETAILED SCORES:\\n\")\n",
    "                for score_name, score_value in validation_result['scores'].items():\n",
    "                    f.write(f\"  {score_name.capitalize()}: {score_value}/10\\n\")\n",
    "                \n",
    "                f.write(\"\\nFULL VALIDATION CONTENT:\\n\")\n",
    "                f.write(\"-\" * 50 + \"\\n\")\n",
    "                f.write(validation_result['validation_content'])\n",
    "            \n",
    "            # Write combined analysis (all information in one file)\n",
    "            combined_out_path = os.path.join(combined_analysis_dir, f\"{num_str}.txt\")\n",
    "            with open(combined_out_path, \"w\", encoding='utf-8') as f:\n",
    "                f.write(\"=\" * 100 + \"\\n\")\n",
    "                f.write(f\"COMPLETE ANALYSIS FOR PROBLEM {num_str}\\n\")\n",
    "                f.write(\"=\" * 100 + \"\\n\\n\")\n",
    "                \n",
    "                f.write(\"PROBLEM DETAILS:\\n\")\n",
    "                f.write(\"-\" * 30 + \"\\n\")\n",
    "                f.write(f\"Question: {question}\\n\")\n",
    "                f.write(f\"Image Path: {image_path}\\n\\n\")\n",
    "                \n",
    "                f.write(\"GENERATED PREDICATES:\\n\")\n",
    "                f.write(\"-\" * 30 + \"\\n\")\n",
    "                if predicates:\n",
    "                    for i, predicate in enumerate(predicates, 1):\n",
    "                        f.write(f\"{i:2d}. {predicate}\\n\")\n",
    "                else:\n",
    "                    f.write(\"No predicates generated\\n\")\n",
    "                f.write(f\"\\nTotal Predicates: {len(predicates)}\\n\\n\")\n",
    "                \n",
    "                f.write(\"STEP-BY-STEP REASONING:\\n\")\n",
    "                f.write(\"-\" * 30 + \"\\n\")\n",
    "                f.write(reasoning + \"\\n\\n\")\n",
    "                \n",
    "                f.write(\"SELF-VALIDATION SUMMARY:\\n\")\n",
    "                f.write(\"-\" * 30 + \"\\n\")\n",
    "                f.write(f\"Overall Assessment: {validation_result['overall_assessment']}\\n\")\n",
    "                f.write(f\"Final Recommendation: {validation_result['final_recommendation']}\\n\")\n",
    "                f.write(f\"Average Score: {validation_result['average_score']:.2f}/10\\n\\n\")\n",
    "                \n",
    "                f.write(\"VALIDATION SCORES BREAKDOWN:\\n\")\n",
    "                for score_name, score_value in validation_result['scores'].items():\n",
    "                    f.write(f\"  • {score_name.capitalize()}: {score_value}/10\\n\")\n",
    "                \n",
    "                f.write(\"\\nDETAILED VALIDATION ANALYSIS:\\n\")\n",
    "                f.write(\"-\" * 30 + \"\\n\")\n",
    "                f.write(validation_result['validation_content'] + \"\\n\\n\")\n",
    "                \n",
    "                f.write(\"RAW LLM OUTPUT:\\n\")\n",
    "                f.write(\"-\" * 30 + \"\\n\")\n",
    "                f.write(raw_content)\n",
    "            \n",
    "            # Log progress\n",
    "            print(f\"✓ Problem {num_str}: {len(predicates)} predicates, Score: {validation_result['average_score']:.1f}/10\")\n",
    "            logging.info(f\"Successfully processed problem {num_str}: {len(predicates)} predicates generated\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error processing problem {num_str}: {str(e)}\"\n",
    "            print(f\"✗ {error_msg}\")\n",
    "            logging.error(error_msg)\n",
    "            \n",
    "            # Write error information to files\n",
    "            for output_dir, filename_prefix in [(predicates_output_dir, \"predicates\"), \n",
    "                                              (reasoning_output_dir, \"reasoning\"), \n",
    "                                              (validation_output_dir, \"validation\"),\n",
    "                                              (combined_analysis_dir, \"combined\")]:\n",
    "                error_file = os.path.join(output_dir, f\"{num_str}.txt\")\n",
    "                with open(error_file, \"w\", encoding='utf-8') as f:\n",
    "                    f.write(f\"ERROR PROCESSING PROBLEM {num_str}\\n\")\n",
    "                    f.write(\"=\" * 50 + \"\\n\")\n",
    "                    f.write(f\"Error: {str(e)}\\n\")\n",
    "                    f.write(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        \n",
    "        # Print usage statistics periodically\n",
    "        if num % 10 == 0:\n",
    "            stats = api_manager.get_usage_stats()\n",
    "            print(f\"\\nAPI Usage Statistics after problem {num}:\")\n",
    "            print(f\"  Total calls used: {stats['total_used']}/{stats['total_available']}\")\n",
    "            print(f\"  Usage percentage: {stats['percent_used']:.1f}%\")\n",
    "            print(f\"  Per-key usage: {stats['per_key']}\")\n",
    "            print()\n",
    "    \n",
    "    # Final statistics and summary\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PROCESSING COMPLETE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    final_stats = api_manager.get_usage_stats()\n",
    "    print(f\"Final API Usage Statistics:\")\n",
    "    print(f\"  Total calls used: {final_stats['total_used']}/{final_stats['total_available']}\")\n",
    "    print(f\"  Usage percentage: {final_stats['percent_used']:.1f}%\")\n",
    "    print(f\"  Per-key usage:\")\n",
    "    for key, usage in final_stats['per_key'].items():\n",
    "        print(f\"    {key[-10:]}: {usage} calls\")\n",
    "    \n",
    "    print(f\"\\nOutput directories:\")\n",
    "    print(f\"  Predicates: {predicates_output_dir}\")\n",
    "    print(f\"  Reasoning: {reasoning_output_dir}\")\n",
    "    print(f\"  Validation: {validation_output_dir}\")\n",
    "    print(f\"  Combined Analysis: {combined_analysis_dir}\")\n",
    "    \n",
    "    logging.info(\"Geometry predicate generation process completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:33:22.488881Z",
     "iopub.status.busy": "2025-07-14T06:33:22.488508Z",
     "iopub.status.idle": "2025-07-14T06:34:05.087125Z",
     "shell.execute_reply": "2025-07-14T06:34:05.086107Z",
     "shell.execute_reply.started": "2025-07-14T06:33:22.488855Z"
    },
    "papermill": {
     "duration": 13481.068572,
     "end_time": "2025-06-18T11:56:43.836497",
     "exception": false,
     "start_time": "2025-06-18T08:12:02.767925",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7590724,
     "sourceId": 12461830,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13505.694243,
   "end_time": "2025-06-18T11:56:45.049332",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-18T08:11:39.355089",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
